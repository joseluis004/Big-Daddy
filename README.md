# üöÄ FinPlus Analytics Challenge: De Datos a Decisiones Accionables (Big-Daddy)

---

## 1. üí° Resumen y Objetivo Estrat√©gico

Este repositorio contiene la soluci√≥n completa √∫nica desarrollada por **Big-Daddy** para  "FinPlus Analytics Challenge". El proyecto se enfoca en la implementaci√≥n de una arquitectura de datos robusta usando Docker y PySpark para generar inteligencia de negocio avanzada.

Nuestro objetivo es transformar los datos crudos de clientes (demogr√°ficos, digitales y transaccionales) en una inteligencia de negocio predictiva y accionable.

### Objetivos Clave de la Soluci√≥n:

| # | Objetivo FinPlus | Resultado de la Soluci√≥n |
| :-: | :--- | :--- |
| **1** | Comprender Clientes | **Segmentaci√≥n Avanzada (Clustering)** para crear perfiles 360¬∞. |
| **2** | Detectar Riesgos | **Modelo Predictivo de Incumplimineto de contratos** asignado a cada cliente. |
| **3** | Oportunidades | **Features RFMI** y m√©tricas de propensi√≥n para impulsar el *cross-selling*. |
| **4** | Toma de Decisiones | **Dashboard Ejecutivo (Tableau)** con KPIs claros y narrativos. |
| **5** | Portal Interactivo | **Aplicaci√≥n Streamlit** para predicciones en tiempo real. |

---

## 2. ‚öôÔ∏è Arquitectura y Dise√±o T√©cnico (Informe 2)

El dise√±o del proyecto utiliza un modelo de **Arquitectura por Capas (Layered Architecture)** y se enfoca en el **Procesamiento por Lotes (Batch Processing)**, priorizando la precisi√≥n para el an√°lisis de comportamiento hist√≥rico (RFMI, Churn).

### 2.1. Arquitectura de Datos y Motor

[Image of Layered Data Architecture]

* **Paradigma:** Arquitectura por Capas, enfoque en Batch Processing.
* **Motor Principal:** **Apache Spark / PySpark**. Es esencial para manejar el Volumen y la Variedad de los datos transaccionales.
* **Almacenamiento Final:** **Master_FINAL_CONSOLIDADO.parquet** en formato Parquet.

### 2.2. Flujo ETL (Extracci√≥n, Transformaci√≥n, Carga)

Es el pipeline de procesamiento que permite Extraer(E), Tranformar(T) y Cargar(L) los datos inciales, opera bajo el motor de PySpark en un flujo modular dentro de la *Curated Layer*.

#### A. Extracci√≥n (E)
Se ingesta la informaci√≥n demogr√°fica/contractual (`CLIENTS.csv`) y el comportamiento transaccional (`BEHAVIOURAL.parquet`) usando DataFrames distribuidos de PySpark.

#### B. Transformaci√≥n (T)
1.  **Limpieza y Normalizaci√≥n:**
    * **Imputaci√≥n Estrat√©gica:** Se rellenan variables de *scoring* o antig√ºedad (CAR AGE, JOB_SENIORITY) con **-1** (valor sentinel).
    * Las variables de historial de pr√©stamo se rellenan con **0** (asumiendo "Sin Historial").
    * Las variables categ√≥ricas (ej., EDUCATION) se rellenan con **'UNKNOWN'**.
    * **Normalizaci√≥n:** Las 10 variables categ√≥ricas se convierten a valores num√©ricos discretos mediante **Label Encoding (StringIndexer)**.
2.  **Feature Engineering:** Creaci√≥n de las 7 dimensiones de valor del cliente:
    * **M√©tricas RFMI:** Recencia (`DAYS SINCE LAST_TXN`), Frecuencia (`FREQUENCY_COUNT`), e Intensidad (`INTENSITY_AVG_SPEND`).
    * **Riesgo Operativo:** C√°lculo del `PAYMENT FIDELITY RATIO`.
    * **Targets ML:** Creaci√≥n de variables binarias `Y` (`Y_RISK_CHURN`) y `T` (`TREATMENT_GROUP`) para modelado Causal (Uplift).

#### C. Carga (L)
Se realiza un **LEFT JOIN** de todos los DataFrames de m√©tricas sobre el Master Base, resultando en la **Vista Consolidada** de 65 columnas (`Master_FINAL_CONSOLIDADO.parquet`).

---

## 3. üë• Roles y Planificaci√≥n Operativa

### 3.1. Roles del Equipo y Responsabilidades Clave

| Miembro | Rol Principal Asignado | Funciones Clave y Tareas Ejecutadas |
| :--- | :--- | :--- |
| **Jose Luis P√©rez** | **Project Lead & Data Architect** | Liderazgo estrat√©gico, gobernanza (GitHub, Docker), documentaci√≥n inicial(README.md) y Modelado predictivo y Dise√±o final del Cuadro de Mando enT ableau. |
| **Claudia Torres** | **Data Engineer (Especialista ETL)** | Implementaci√≥n del flujo ETL en PySpark, limpieza de datos, imputaci√≥n estrat√©gica y creaci√≥n de la Curated Layer. |
| **N√∫ria Mayoral** | **Data Analyst** | Desarrollo de la l√≥gica de los 7 indicadores de comportamiento (RFMI, Riesgo, Anomal√≠a, etc.) y la segmentaci√≥n. |
| **Benjam√≠n Carbonell** | **ML Specialist & Visualization Analyst** | Desarrollo y entrenamiento de los modelos predictivos. Implementaci√≥n y construcci√≥n de *dashboards* en Tableau. |

### 3.2. Planificaci√≥n Operativa (Roadmap Semanal)

El proyecto se desarroll√≥ con un enfoque √°gil en 3 semanas:

| Semana | Fases del Trabajo | Tareas Clave y Foco Principal | Responsable(s) Principal(es) |
| :--- | :--- | :--- | :--- |
| **Semana 1** | Fundaci√≥n T√©cnica y ETL | Crear el entorno Docker, montar el repositorio en GitHub. Ingesta de datos, auditor√≠a, imputaci√≥n de nulos y ejecuci√≥n del ETL de limpieza inicial. | Jose Luis, Claudia |
| **Semana 2** | Modelado y An√°lisis Avanzado | Calcular los 7 indicadores de comportamiento. Crear variables $Y/T$ y entrenar los modelos predictivos. | N√∫ria, Benjam√≠n, Jose Luis |
| **Semana 3** | Visualizaci√≥n y Documentaci√≥n | Construir los 7 Cuadros de Mando en Tableau. Desarrollo del portal interactivo Streamlit. Redacci√≥n final de la documentaci√≥n. | Benjam√≠n, Jose Luis, Claudia, N√∫ria |

#### Puntos de Control Clave (Milestones)

| Milestone | Resultado Obtenido |
| :--- | :--- |
| **M1: Entorno Operativo** | Entorno t√©cnico configurado. |
| **M2: Master View Lista** | Capa Curada creada y validada. |
| **M3: Inteligencia Anal√≠tica** | Todos los 7 indicadores calculados y Modelos Predictivos entrenados. |
| **M4: Portal Interactivo** | Aplicaci√≥n Streamlit desplegada y operativa. |
| **M5: Soluci√≥n Completa** | Documentaci√≥n y 6 Dashboards de Tableau finalizados. |

---

## 4. üõ†Ô∏è Gu√≠a de Instalaci√≥n y Ejecuci√≥n del Pipeline

### Control de Versiones
Utilizamos **GitHub** para el control de versiones, asegurando que el c√≥digo sea reproducible, documentado, y que cada cambio sea trazable, cumpliendo con la Verificabilidad.

### Requisitos Previos

1.  **Git** (para clonar el repositorio).
2.  **Docker Desktop** (para el entorno reproducible).

### 4.1. Puesta en Marcha del Entorno

1.  **Clonar el Repositorio:**
    ```bash
    git clone https://github.com/joseluis004/Big-Daddy.git
    cd Big-Daddy/
    ```

2.  **Navegar a la Carpeta de Configuraci√≥n Docker:**
    ```bash
    cd docker_big_daddy/
    ```

3.  **Construir el Entorno (Instala PySpark, Python, librer√≠as):**
    ```bash
    docker-compose build
    ```

4.  **Ejecutar el Contenedor (Inicia JupyterLab):**
    ```bash
    docker-compose up
    ```
    *Una vez iniciado, acceda al enlace `http://localhost:8888` (o el que se muestre en la terminal) en su navegador para entrar a JupyterLab.*

### 4.2. Ejecuci√≥n del Pipeline Anal√≠tico

El proceso de ETL, Feature Engineering y Modelado se realiza mediante la ejecuci√≥n secuencial de los Notebooks dentro del contenedor de JupyterLab.

1.  En la interfaz de JupyterLab, navegue a la carpeta **`notebooks/`**.
2.  **Paso 1: TRATAMIENTO DE DATOS**
    * Abrir y ejecutar completamente el notebook **`TRATAMIENTO DE DATOS.ipynb`**.
    * *Resultado:* Carga los datos, realiza la limpieza, ingenier√≠a de features y genera m√∫ltiples archivos Parquet de resultados. Los modelos predictivos posteriormente ejecutar√°n el archivo **`Master_Model_FinPlus.parquet`** que se encuentra en `data/curated/`.
3.  **Paso 2: MODELOS PREDICTIVOS**
    * Abrir y ejecutar completamente el notebook **`MODELOS PREDICTIVOS.ipynb`**.
    * *Resultado:* Utiliza los datos procesados para entrenar y evaluar los modelos. **Importante:** Se entrenaron y evaluaron dos modelos para la predicci√≥n de churn: **XGBoost** y una **Red Neuronal**. Dado que el modelo XGBoost demostr√≥ un mejor desempe√±o en t√©rminos de precisi√≥n, fue seleccionado como el modelo final para la implementaci√≥n en producci√≥n. Sin embargo, ambos modelos est√°n disponibles en el repositorio.
### 4.3. Portal Interactivo FinPlus

Hemos desarrollado un portal interactivo utilizando **Streamlit** que permite cargar nuevos datos en formato CSV y obtener predicciones del modelo XGBoost en tiempo real.

**üîó Acceso al Portal:**
- **URL:** [big-daddy-episjsskxsskkkuyuaq7iv.streamlit.app](https://big-daddy-episjsskxsskkkuyuaq7iv.streamlit.app)

**Funcionalidades del Portal:**
- **Carga de Datos:** Interfaz intuitiva para subir archivos CSV con datos de clientes.
- **Predicci√≥n en Tiempo Real:** El modelo XGBoost entrenado realiza predicciones de churn score inmediatamente.
- **Visualizaci√≥n de Resultados:** Muestra las probabilidades de abandono para cada cliente.
- **Descarga de Resultados:** Permite exportar las predicciones para su uso posterior.

---

## 5. üîó Entregables y Resultados

| Entregable | Contenido | Ubicaci√≥n |
| :--- | :--- | :--- |
| **Documentaci√≥n** | Propuesta Inicial, Fundamentos y Diagrama de Arquitectura. | `docs/` |
| **C√≥digo Fuente** | Repositorio completo (commits y PRs). | [GitHub: Big-Daddy](https://github.com/joseluis004/Big-Daddy) |
| **C√≥digo ETL** | Limpieza y Feature Engineering con PySpark. | `notebooks/TRATAMIENTO DE DATOS.ipynb` |
| **C√≥digo Modelado** | Xgboost, Red neuronal. | `notebooks/MODELOS PREDICTIVOS.ipynb` |
| **Portal Interactivo** | Aplicaci√≥n Streamlit para predicciones en tiempo real. | [Portal FinPlus](https://big-daddy-episjsskxsskkkuyuaq7iv.streamlit.app) |
| **Visualizaci√≥n/Servicio** | 6 Dashboards Ejecutivos implementados en Tableau Public. | [Dashboard 1: Anomaly Class](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_1/DashboardANOMALYCLASS)<br>[Dashboard 2: Riesgo Abandono](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_2/DashboardRIESGOABANDONO)<br>[Dashboard 3: Barras de Actividad](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_3/DashboardBARRASDEACTIVIDAD)<br>[Dashboard 4: Barras Apiladas de Valor](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_4/DashboardBARRASAPILADASDEVALOR)<br>[Dashboard 5: Barras Agrupadas de Interacci√≥n](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_5/DashboardBARRASAGRUPADASDEINTERACCIN)<br>[Dashboard 6: Dispersi√≥n de Riesgo](https://public.tableau.com/app/profile/jose.luis.perez3391/viz/Big_Daddy_dashboards_6/DashboardDISPERSINDERIESGO) |

**¬°Gracias por su tiempo! Esperamos convertirnos en su socio anal√≠tico 2025.**
