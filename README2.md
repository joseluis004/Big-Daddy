# üöÄ FinPlus Analytics Challenge: De Datos a Decisiones Accionables (Big-Daddy)

<p align="center">
¬† <img src="https://img.shields.io/badge/Tecnolog√≠a-PySpark%2FDocker-blue" alt="PySpark Badge"/>
¬† <img src="https://img.shields.io/badge/Metodolog√≠a-Layered%20Architecture-informational" alt="Layered Architecture Badge"/>
¬† <img src="https://img.shields.io/badge/An√°lisis-Churn%20Score%20%2F%20RFMI-success" alt="Analysis Badge"/>
¬† <img src="https://img.shields.io/badge/Status-Completado-brightgreen" alt="Status Badge"/>
</p>

---

## 1. üí° Resumen y Objetivo Estrat√©gico

Este repositorio contiene la soluci√≥n completa *end-to-end* desarrollada por **Big-Daddy** para el "FinPlus Analytics Challenge". El proyecto se enfoca en la implementaci√≥n de una arquitectura de datos robusta usando Docker y PySpark para generar inteligencia de negocio avanzada.

Nuestro objetivo es transformar los datos crudos de clientes (demogr√°ficos, digitales y transaccionales) en una **inteligencia de negocio predictiva y accionable**.

### Objetivos Clave de la Soluci√≥n:

| # | Objetivo FinPlus | Resultado de la Soluci√≥n |
| :-: | :--- | :--- |
| **1** | Comprender Clientes | **Segmentaci√≥n Avanzada (Clustering)** para crear perfiles 360¬∞. |
| **2** | Detectar Riesgos | **Modelo Predictivo de Abandono (Churn Score)** asignado a cada cliente. |
| **3** | Oportunidades | **Features RFMI** y m√©tricas de propensi√≥n para impulsar el *cross-selling*. |
| **4** | Toma de Decisiones | **Dashboard Ejecutivo (Tableau)** con KPIs claros y narrativos. |

---

## 2. ‚öôÔ∏è Arquitectura y Dise√±o T√©cnico (Informe 2)

El dise√±o del proyecto utiliza un modelo de **Arquitectura por Capas (Layered Architecture)** y se enfoca en el **Procesamiento por Lotes (Batch Processing)**, priorizando la precisi√≥n para el an√°lisis de comportamiento hist√≥rico (RFMI, Churn).

### 2.1. Arquitectura de Datos y Motor



[Image of Layered Data Architecture]


* **Paradigma:** Arquitectura por Capas, enfoque en Batch Processing.
* **Motor Principal:** **Apache Spark / PySpark**. Es esencial para manejar el Volumen y la Variedad de los datos transaccionales.
* **Almacenamiento Final:** **Master\_FINAL\_CONSOLIDADO.parquet** en formato **Parquet**. Este formato columnar optimiza la compresi√≥n y la velocidad de consulta en la capa de BI y Machine Learning.

### 2.2. Flujo ETL (Extracci√≥n, Transformaci√≥n, Carga)

El flujo modular se implementa en PySpark dentro de la *Curated Layer*.

#### A. Extracci√≥n (E)
Se ingesta la informaci√≥n demogr√°fica/contractual (`CLIENTS.csv`) y el comportamiento transaccional (`BEHAVIOURAL.parquet`) usando DataFrames distribuidos de PySpark.

#### B. Transformaci√≥n (T)
1.¬† **Limpieza y Normalizaci√≥n:**
    * **Imputaci√≥n Estrat√©gica:** Se rellenan variables de *scoring* o antig√ºedad (CAR AGE, JOB\_SENIORITY) con **-1** (valor sentinel).
    * Las variables de historial de pr√©stamo se rellenan con **0** (asumiendo "Sin Historial").
    * Las variables categ√≥ricas (ej., EDUCATION) se rellenan con **'UNKNOWN'**.
    * **Normalizaci√≥n:** Las 10 variables categ√≥ricas se convierten a valores num√©ricos discretos mediante **Label Encoding (StringIndexer)**.
2.¬† **Feature Engineering:** Creaci√≥n de las 7 dimensiones de valor del cliente:
    * **M√©tricas RFMI:** Recencia (`DAYS SINCE LAST_TXN`), Frecuencia (`FREQUENCY_COUNT`), e Intensidad (`INTENSITY_AVG_SPEND`).
    * **Riesgo Operativo:** C√°lculo del `PAYMENT FIDELITY RATIO`.
    * **Targets ML:** Creaci√≥n de variables binarias `Y` (`Y_RISK_CHURN`) y `T` (`TREATMENT_GROUP`) para modelado Causal (Uplift).

#### C. Carga (L)
Se realiza un **LEFT JOIN** de todos los DataFrames de m√©tricas sobre el Master Base, resultando en la **Vista Consolidada** de 65 columnas (`Master_FINAL_CONSOLIDADO.parquet`).

---

## 3. üë• Roles y Planificaci√≥n Operativa

### 3.1. Roles del Equipo y Responsabilidades Clave

| Miembro | Rol Principal Asignado | Funciones Clave y Tareas Ejecutadas |
| :--- | :--- | :--- |
| **Jose Luis P√©rez** | **Project Lead & Data Architect** | Liderazgo estrat√©gico, gobernanza (GitHub, Docker), y dise√±o final del Cuadro de Mando en Tableau. |
| **Claudia Torres** | **Data Engineer (Especialista ETL)** | Implementaci√≥n del flujo ETL en PySpark, limpieza de datos, imputaci√≥n estrat√©gica y creaci√≥n de la Curated Layer. |
| **N√∫ria Mayoral** | **Data Analyst** | Desarrollo de la l√≥gica de los 7 indicadores de comportamiento (RFMI, Riesgo, Anomal√≠a, etc.) y la segmentaci√≥n. |
| **Benjam√≠n Carbonell** | **ML Specialist & Visualization Analyst** | Desarrollo y entrenamiento de los modelos predictivos. Implementaci√≥n y construcci√≥n de *dashboards* en Tableau. |

### 3.2. Planificaci√≥n Operativa (Roadmap Semanal)

El proyecto se desarroll√≥ con un enfoque √°gil en 3 semanas:

| Semana | Fases del Trabajo | Tareas Clave y Foco Principal | Responsable(s) Principal(es) |
| :--- | :--- | :--- | :--- |
| **Semana 1** | Fundaci√≥n T√©cnica y ETL | Crear el entorno Docker, montar el repositorio en GitHub. Ingesta de datos, auditor√≠a, imputaci√≥n de nulos y ejecuci√≥n del ETL de limpieza inicial. | Jose Luis, Claudia |
| **Semana 2** | Modelado y An√°lisis Avanzado | Calcular los 7 indicadores de comportamiento. Crear variables $Y/T$ y entrenar los modelos predictivos. | N√∫ria, Benjam√≠n, Jose Luis |
| **Semana 3** | Visualizaci√≥n y Documentaci√≥n | Construir los 7 Cuadros de Mando en Tableau. Redacci√≥n final de la documentaci√≥n. | Benjam√≠n, Jose Luis, Claudia, N√∫ria |

#### Puntos de Control Clave (Milestones)

| Milestone | Resultado Obtenido |
| :--- | :--- |
| **M1: Entorno Operativo** | Entorno t√©cnico configurado. |
| **M2: Master View Lista** | Capa Curada creada y validada. |
| **M3: Inteligencia Anal√≠tica** | Todos los 7 indicadores calculados y Modelos Predictivos entrenados. |
| **M4: Soluci√≥n Completa** | Documentaci√≥n y 7 Dashboards de Tableau finalizados. |

---

## 4. üõ†Ô∏è Gu√≠a de Instalaci√≥n y Ejecuci√≥n del Pipeline

### Control de Versiones
Utilizamos **GitHub** para el control de versiones, asegurando que el c√≥digo sea reproducible, documentado, y que cada cambio sea trazable, cumpliendo con la Verificabilidad.

### Requisitos Previos

1.  **Git** (para clonar el repositorio).
2.  **Docker Desktop** (para el entorno reproducible).

### 4.1. Puesta en Marcha del Entorno

1.¬† **Clonar el Repositorio:**
¬† ¬† ```bash
¬† ¬† git clone [https://github.com/joseluis004/Big-Daddy.git](https://github.com/joseluis004/Big-Daddy.git)
¬† ¬† cd Big-Daddy/
¬† ¬† ```

2.¬† **Navegar a la Carpeta de Configuraci√≥n Docker:**
¬† ¬† ```bash
¬† ¬† cd docker_big_daddy/
¬† ¬† ```

3.¬† **Construir el Entorno (Instala PySpark, Python, librer√≠as):**
¬† ¬† ```bash
¬† ¬† docker-compose build
¬† ¬† ```

4.¬† **Ejecutar el Contenedor (Inicia JupyterLab):**
¬† ¬† ```bash
¬† ¬† docker-compose up
¬† ¬† ```
¬† ¬† *Una vez iniciado, acceda al enlace `http://localhost:8888` (o el que se muestre en la terminal) en su navegador para entrar a JupyterLab.*

### 4.2. Ejecuci√≥n del Pipeline Anal√≠tico

El proceso de ETL, Feature Engineering y Modelado se realiza mediante la ejecuci√≥n secuencial de los Notebooks dentro del contenedor de JupyterLab.

1.¬† En la interfaz de JupyterLab, navegue a la carpeta **`notebooks/`**.

2.¬† **Paso 1: TRATAMIENTO DE DATOS**
    * Abrir y ejecutar completamente el notebook **`TRATAMIENTO DE DATOS.ipynb`**.
    * *Resultado:* Carga los datos, realiza la limpieza, ingenier√≠a de features y guarda los resultados en la Capa Silver/Gold.

3.¬† **Paso 2: MODELOS PREDICTIVOS**
    * Abrir y ejecutar completamente el notebook **`MODELOS PREDICTIVOS.ipynb`**.
    * *Resultado:* Utiliza los datos procesados para entrenar y evaluar los modelos (Clustering y Churn Score).

---

## 5. üîó Entregables y Resultados

| Entregable | Contenido | Ubicaci√≥n |
| :--- | :--- | :--- |
| **Documentaci√≥n** | Propuesta Inicial, Fundamentos y Diagrama de Arquitectura. | `docs/` |
| **C√≥digo Fuente** | Repositorio completo (commits y PRs). | [GitHub: Big-Daddy](https://github.com/joseluis004/Big-Daddy) |
| **C√≥digo ETL** | Limpieza y Feature Engineering con PySpark. | `notebooks/TRATAMIENTO DE DATOS.ipynb` |
| **C√≥digo Modelado** | Clustering, Churn Score. | `notebooks/MODELOS PREDICTIVOS.ipynb` |
| **Visualizaci√≥n/Servicio** | Aplicaci√≥n o Dashboard Ejecutivo (Implementado en Tableau). | `portal_app/` y [**LINK AL DASHBOARD** (Tableau/PowerBI)] |

**¬°Gracias por su tiempo! Esperamos convertirnos en su socio anal√≠tico 2025.**