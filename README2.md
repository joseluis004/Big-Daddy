# ğŸš€ FinPlus Analytics Challenge: De Datos a Decisiones Accionables (Big-Daddy)

<p align="center">
Â  <img src="https://img.shields.io/badge/TecnologÃ­a-PySpark%2FDocker-blue" alt="PySpark Badge"/>
Â  <img src="https://img.shields.io/badge/MetodologÃ­a-Layered%20Architecture-informational" alt="Layered Architecture Badge"/>
Â  <img src="https://img.shields.io/badge/AnÃ¡lisis-Churn%20Score%20%2F%20RFMI-success" alt="Analysis Badge"/>
Â  <img src="https://img.shields.io/badge/Status-Completado-brightgreen" alt="Status Badge"/>
</p>

---

## 1. ğŸ’¡ Resumen y Objetivo EstratÃ©gico

[cite_start]Este repositorio contiene la soluciÃ³n completa *end-to-end* desarrollada por **Big-Daddy** para el "FinPlus Analytics Challenge"[cite: 5, 7]. [cite_start]El proyecto se enfoca en la implementaciÃ³n de una arquitectura de datos robusta usando Docker y PySpark para generar inteligencia de negocio avanzada[cite: 28, 79].

[cite_start]Nuestro objetivo es transformar los datos crudos de clientes (demogrÃ¡ficos, digitales y transaccionales) en una **inteligencia de negocio predictiva y accionable**[cite: 67].

### Objetivos Clave de la SoluciÃ³n:

| # | Objetivo FinPlus | Resultado de la SoluciÃ³n |
| :-: | :--- | :--- |
| **1** | Comprender Clientes | **SegmentaciÃ³n Avanzada (Clustering)** para crear perfiles 360Â°. |
| **2** | Detectar Riesgos | [cite_start]**Modelo Predictivo de Abandono (Churn Score)** asignado a cada cliente[cite: 29]. |
| **3** | Oportunidades | [cite_start]**Features RFMI** y mÃ©tricas de propensiÃ³n para impulsar el *cross-selling*[cite: 52]. |
| **4** | Toma de Decisiones | [cite_start]**Dashboard Ejecutivo (Tableau)** con KPIs claros y narrativos[cite: 68]. |

---

## 2. âš™ï¸ Arquitectura y DiseÃ±o TÃ©cnico (Informe 2)

[cite_start]El diseÃ±o del proyecto utiliza un modelo de **Arquitectura por Capas (Layered Architecture)** [cite: 25] [cite_start]y se enfoca en el **Procesamiento por Lotes (Batch Processing)** [cite: 25][cite_start], priorizando la precisiÃ³n para el anÃ¡lisis de comportamiento histÃ³rico (RFMI, Churn)[cite: 29].

### 2.1. Arquitectura de Datos y Motor



[Image of Layered Data Architecture]


* [cite_start]**Paradigma:** Arquitectura por Capas, enfoque en Batch Processing[cite: 25].
* [cite_start]**Motor Principal:** **Apache Spark / PySpark**[cite: 28]. [cite_start]Es esencial para manejar el Volumen y la Variedad de los datos transaccionales[cite: 28].
* [cite_start]**Almacenamiento Final:** **Master\_FINAL\_CONSOLIDADO.parquet** [cite: 59] [cite_start]en formato **Parquet**[cite: 62]. [cite_start]Este formato columnar optimiza la compresiÃ³n y la velocidad de consulta en la capa de BI y Machine Learning[cite: 65].

### 2.2. Flujo ETL (ExtracciÃ³n, TransformaciÃ³n, Carga)

[cite_start]El flujo modular se implementa en PySpark dentro de la *Curated Layer*[cite: 32].



#### A. ExtracciÃ³n (E)
[cite_start]Se ingesta la informaciÃ³n demogrÃ¡fica/contractual (`CLIENTS.csv`) y el comportamiento transaccional (`BEHAVIOURAL.parquet`) [cite: 34] [cite_start]usando DataFrames distribuidos de PySpark[cite: 35].

#### B. TransformaciÃ³n (T)
1.  **Limpieza y NormalizaciÃ³n:**
    * [cite_start]**ImputaciÃ³n EstratÃ©gica:** Se rellenan variables de *scoring* o antigÃ¼edad (CAR AGE, JOB\_SENIORITY) con **-1** (valor sentinel)[cite: 41].
    * [cite_start]Las variables de historial de prÃ©stamo se rellenan con **0** (asumiendo "Sin Historial")[cite: 42].
    * [cite_start]Las variables categÃ³ricas (ej., EDUCATION) se rellenan con **'UNKNOWN'**[cite: 43].
    * [cite_start]**NormalizaciÃ³n:** Las 10 variables categÃ³ricas se convierten a valores numÃ©ricos discretos mediante **Label Encoding (StringIndexer)**[cite: 44].
2.  [cite_start]**Feature Engineering:** CreaciÃ³n de las 7 dimensiones de valor del cliente[cite: 51]:
    * [cite_start]**MÃ©tricas RFMI:** Recencia (`DAYS SINCE LAST_TXN`), Frecuencia (`FREQUENCY_COUNT`), e Intensidad (`INTENSITY_AVG_SPEND`)[cite: 52].
    * [cite_start]**Riesgo Operativo:** CÃ¡lculo del `PAYMENT FIDELITY RATIO`[cite: 53].
    * [cite_start]**Targets ML:** CreaciÃ³n de variables binarias `Y` (`Y_RISK_CHURN`) y `T` (`TREATMENT_GROUP`) para modelado Causal (Uplift)[cite: 55].

#### C. Carga (L)
[cite_start]Se realiza un **LEFT JOIN** de todos los DataFrames de mÃ©tricas [cite: 58] [cite_start]sobre el Master Base, resultando en la **Vista Consolidada** de 65 columnas (`Master_FINAL_CONSOLIDADO.parquet`)[cite: 59, 60].

---

## 3. ğŸ‘¥ Roles y PlanificaciÃ³n Operativa

### 3.1. Roles del Equipo y Responsabilidades Clave

| Miembro | Rol Principal Asignado | Funciones Clave y Tareas Ejecutadas |
| :--- | :--- | :--- |
| **Jose Luis PÃ©rez** | **Project Lead & Data Architect** | [cite_start]Liderazgo estratÃ©gico, gobernanza (GitHub, Docker) [cite: 75][cite_start], y diseÃ±o final del Cuadro de Mando en Tableau[cite: 75]. |
| **Claudia Torres** | **Data Engineer (Especialista ETL)** | [cite_start]ImplementaciÃ³n del flujo ETL en PySpark, limpieza de datos, imputaciÃ³n estratÃ©gica y creaciÃ³n de la Curated Layer[cite: 75]. |
| **NÃºria Mayoral** | **Data Analyst** | [cite_start]Desarrollo de la lÃ³gica de los 7 indicadores de comportamiento (RFMI, Riesgo, AnomalÃ­a, etc.) y la segmentaciÃ³n[cite: 75]. |
| **BenjamÃ­n Carbonell** | **ML Specialist & Visualization Analyst** | [cite_start]Desarrollo y entrenamiento de los modelos predictivos[cite: 75]. [cite_start]ImplementaciÃ³n y construcciÃ³n de *dashboards* en Tableau[cite: 75]. |

### 3.2. PlanificaciÃ³n Operativa (Roadmap Semanal)

[cite_start]El proyecto se desarrollÃ³ con un enfoque Ã¡gil en 3 semanas[cite: 77]:

| Semana | Fases del Trabajo | Tareas Clave y Foco Principal | Responsable(s) Principal(es) |
| :--- | :--- | :--- | :--- |
| **Semana 1** | FundaciÃ³n TÃ©cnica y ETL | Crear el entorno Docker, montar el repositorio en GitHub. [cite_start]Ingesta de datos, auditorÃ­a, imputaciÃ³n de nulos y ejecuciÃ³n del ETL de limpieza inicial[cite: 79]. | [cite_start]Jose Luis, Claudia [cite: 79] |
| **Semana 2** | Modelado y AnÃ¡lisis Avanzado | Calcular los 7 indicadores de comportamiento. [cite_start]Crear variables $Y/T$ y entrenar los modelos predictivos[cite: 79]. | [cite_start]NÃºria, BenjamÃ­n, Jose Luis [cite: 79] |
| **Semana 3** | VisualizaciÃ³n y DocumentaciÃ³n | Construir los 7 Cuadros de Mando en Tableau. [cite_start]RedacciÃ³n final de la documentaciÃ³n[cite: 79]. | [cite_start]BenjamÃ­n, Jose Luis, Claudia, NÃºria [cite: 79] |

#### Puntos de Control Clave (Milestones)

| Milestone | Resultado Obtenido |
| :--- | :--- |
| **M1: Entorno Operativo** | [cite_start]Entorno tÃ©cnico configurado[cite: 87]. |
| **M2: Master View Lista** | [cite_start]Capa Curada creada y validada[cite: 87]. |
| **M3: Inteligencia AnalÃ­tica** | [cite_start]Todos los 7 indicadores calculados y Modelos Predictivos entrenados[cite: 87]. |
| **M4: SoluciÃ³n Completa** | [cite_start]DocumentaciÃ³n y 7 Dashboards de Tableau finalizados[cite: 87]. |

---

## 4. ğŸ› ï¸ GuÃ­a de InstalaciÃ³n y EjecuciÃ³n del Pipeline

### Control de Versiones
[cite_start]Utilizamos **GitHub** para el control de versiones, asegurando que el cÃ³digo sea reproducible, documentado, y que cada cambio sea trazable, cumpliendo con la Verificabilidad[cite: 89, 90].

### Requisitos Previos

1.Â  **Git** (para clonar el repositorio).
2.Â  **Docker Desktop** (para el entorno reproducible).

### 4.1. Puesta en Marcha del Entorno

1.Â  **Clonar el Repositorio:**
Â  Â  ```bash
Â  Â  git clone [https://github.com/joseluis004/Big-Daddy.git](https://github.com/joseluis004/Big-Daddy.git)
Â  Â  cd Big-Daddy/
Â  Â  ```

2.Â  **Navegar a la Carpeta de ConfiguraciÃ³n Docker:**
Â  Â  ```bash
Â  Â  cd docker_big_daddy/
Â  Â  ```

3.Â  **Construir el Entorno (Instala PySpark, Python, librerÃ­as):**
Â  Â  ```bash
Â  Â  docker-compose build
Â  Â  ```

4.Â  **Ejecutar el Contenedor (Inicia JupyterLab):**
Â  Â  ```bash
Â  Â  docker-compose up
Â  Â  ```
Â  Â  *Una vez iniciado, acceda al enlace `http://localhost:8888` (o el que se muestre en la terminal) en su navegador para entrar a JupyterLab.*

### 4.2. EjecuciÃ³n del Pipeline AnalÃ­tico

El proceso de ETL, Feature Engineering y Modelado se realiza mediante la ejecuciÃ³n secuencial de los Notebooks dentro del contenedor de JupyterLab.

1.Â  En la interfaz de JupyterLab, navegue a la carpeta **`notebooks/`**.

2.Â  **Paso 1: TRATAMIENTO DE DATOS**
Â  Â  * Abrir y ejecutar completamente el notebook **`TRATAMIENTO DE DATOS.ipynb`**.
Â  Â  * *Resultado:* Carga los datos, realiza la limpieza, ingenierÃ­a de features y guarda los resultados en la Capa Silver/Gold.

3.Â  **Paso 2: MODELOS PREDICTIVOS**
Â  Â  * Abrir y ejecutar completamente el notebook **`MODELOS PREDICTIVOS.ipynb`**.
Â  Â  * *Resultado:* Utiliza los datos procesados para entrenar y evaluar los modelos (Clustering y Churn Score).

---

## 5. ğŸ”— Entregables y Resultados

| Entregable | Contenido | UbicaciÃ³n |
| :--- | :--- | :--- |
| **DocumentaciÃ³n** | Propuesta Inicial, Fundamentos y Diagrama de Arquitectura. | `docs/` |
| **CÃ³digo Fuente** | Repositorio completo (commits y PRs). | [GitHub: Big-Daddy](https://github.com/joseluis004/Big-Daddy) |
| **CÃ³digo ETL** | Limpieza y Feature Engineering con PySpark. | `notebooks/TRATAMIENTO DE DATOS.ipynb` |
| **CÃ³digo Modelado** | Clustering, Churn Score. | `notebooks/MODELOS PREDICTIVOS.ipynb` |
| **VisualizaciÃ³n/Servicio** | [cite_start]AplicaciÃ³n o Dashboard Ejecutivo (Implementado en Tableau)[cite: 68]. | `portal_app/` y [**LINK AL DASHBOARD** (Tableau/PowerBI)] |

**Â¡Gracias por su tiempo! Esperamos convertirnos en su socio analÃ­tico 2025.**