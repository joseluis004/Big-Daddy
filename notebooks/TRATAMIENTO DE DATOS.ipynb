{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "7887eb35",
   "metadata": {},
   "source": [
    "# TRATAMIENTO DE DATOS CON PYSPARK"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "42038e2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. CONFIGURACIÓN E IMPORTACIONES\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql import functions as F\n",
    "from pyspark.sql import types as T\n",
    "from pyspark.sql.window import Window\n",
    "\n",
    "# Iniciamos Spark\n",
    "spark = SparkSession.builder \\\n",
    "    .appName(\"FinPlus_ETL_Limpieza\") \\\n",
    "    .getOrCreate()\n",
    "\n",
    "# Rutas de los datos\n",
    "DATA_PATH = \"/home/jovyan/work/data/\"  \n",
    "OUTPUT_PATH = \"/home/jovyan/work/data/curated/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "bc0c06d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esquema Clients:\n",
      "root\n",
      " |-- CLIENT_ID: string (nullable = true)\n",
      " |-- NON_COMPLIANT_CONTRACT: integer (nullable = true)\n",
      " |-- NAME_PRODUCT_TYPE: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- TOTAL_INCOME: double (nullable = true)\n",
      " |-- AMOUNT_PRODUCT: double (nullable = true)\n",
      " |-- INSTALLMENT: double (nullable = true)\n",
      " |-- EDUCATION: string (nullable = true)\n",
      " |-- MARITAL_STATUS: string (nullable = true)\n",
      " |-- HOME_SITUATION: string (nullable = true)\n",
      " |-- REGION_SCORE: double (nullable = true)\n",
      " |-- AGE_IN_YEARS: double (nullable = true)\n",
      " |-- JOB_SENIORITY: double (nullable = true)\n",
      " |-- HOME_SENIORITY: double (nullable = true)\n",
      " |-- LAST_UPDATE: double (nullable = true)\n",
      " |-- OWN_INSURANCE_CAR: string (nullable = true)\n",
      " |-- CAR_AGE: double (nullable = true)\n",
      " |-- FAMILY_SIZE: double (nullable = true)\n",
      " |-- REACTIVE_SCORING: double (nullable = true)\n",
      " |-- PROACTIVE_SCORING: double (nullable = true)\n",
      " |-- BEHAVIORAL_SCORING: double (nullable = true)\n",
      " |-- DAYS_LAST_INFO_CHANGE: double (nullable = true)\n",
      " |-- NUMBER_OF_PRODUCTS: double (nullable = true)\n",
      " |-- OCCUPATION: string (nullable = true)\n",
      " |-- DIGITAL_CLIENT: integer (nullable = true)\n",
      " |-- HOME_OWNER: string (nullable = true)\n",
      " |-- EMPLOYER_ORGANIZATION_TYPE: string (nullable = true)\n",
      " |-- CURRENCY: string (nullable = true)\n",
      " |-- NUM_PREVIOUS_LOAN_APP: double (nullable = true)\n",
      " |-- LOAN_ANNUITY_PAYMENT_MAX: double (nullable = true)\n",
      " |-- LOAN_ANNUITY_PAYMENT_MIN: double (nullable = true)\n",
      " |-- LOAN_ANNUITY_PAYMENT_SUM: double (nullable = true)\n",
      " |-- LOAN_APPLICATION_AMOUNT_MAX: double (nullable = true)\n",
      " |-- LOAN_APPLICATION_AMOUNT_MIN: double (nullable = true)\n",
      " |-- LOAN_APPLICATION_AMOUNT_SUM: double (nullable = true)\n",
      " |-- LOAN_CREDIT_GRANTED_MAX: double (nullable = true)\n",
      " |-- LOAN_CREDIT_GRANTED_MIN: double (nullable = true)\n",
      " |-- LOAN_CREDIT_GRANTED_SUM: double (nullable = true)\n",
      " |-- LOAN_VARIABLE_RATE_MAX: double (nullable = true)\n",
      " |-- LOAN_VARIABLE_RATE_MIN: double (nullable = true)\n",
      " |-- NUM_STATUS_ANNULLED: double (nullable = true)\n",
      " |-- NUM_STATUS_AUTHORIZED: double (nullable = true)\n",
      " |-- NUM_STATUS_DENIED: double (nullable = true)\n",
      " |-- NUM_STATUS_NOT_USED: double (nullable = true)\n",
      " |-- NUM_FLAG_INSURED: double (nullable = true)\n",
      "\n",
      "Esquema Behavioural:\n",
      "root\n",
      " |-- CONTRACT_ID: string (nullable = true)\n",
      " |-- CLIENT_ID: string (nullable = true)\n",
      " |-- DATE: string (nullable = true)\n",
      " |-- CREDICT_CARD_BALANCE: double (nullable = true)\n",
      " |-- CREDIT_CARD_LIMIT: double (nullable = true)\n",
      " |-- CREDIT_CARD_DRAWINGS_ATM: double (nullable = true)\n",
      " |-- CREDIT_CARD_DRAWINGS: double (nullable = true)\n",
      " |-- CREDIT_CARD_DRAWINGS_POS: double (nullable = true)\n",
      " |-- CREDIT_CARD_DRAWINGS_OTHER: double (nullable = true)\n",
      " |-- CREDIT_CARD_PAYMENT: double (nullable = true)\n",
      " |-- NUMBER_DRAWINGS_ATM: double (nullable = true)\n",
      " |-- NUMBER_DRAWINGS: long (nullable = true)\n",
      " |-- NUMBER_INSTALMENTS: double (nullable = true)\n",
      " |-- CURRENCY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 2. INGESTA DE DATOS \n",
    "\n",
    "# Cargar CLIENTS.csv\n",
    "# Usamos header=True para leer la cabecera e inferSchema=True para detectar números\n",
    "df_clients = spark.read.csv(DATA_PATH + \"CLIENTS.csv\", header=True, inferSchema=True, sep=',')\n",
    "\n",
    "# Cargar BEHAVIOURAL.parquet\n",
    "df_behav = spark.read.parquet(DATA_PATH + \"BEHAVIOURAL.parquet\")\n",
    "\n",
    "# Verificamos qué columnas tenemos \n",
    "print(\"Esquema Clients:\")\n",
    "df_clients.printSchema()\n",
    "\n",
    "print(\"Esquema Behavioural:\")\n",
    "df_behav.printSchema()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "38cda49f",
   "metadata": {},
   "source": [
    "Primero analizamos las variables de tipo string. Hay de distintos tipos:\n",
    "\n",
    "- Categóricas puras: \"NAME_PRODUCT_TYPE\", \"GENDER\", \"EDUCATION\", \"MARITAL_STATUS\", \n",
    "    \"HOME_SITUATION\", \"OWN_INSURANCE_CAR\", \"OCCUPATION\", \n",
    "    \"HOME_OWNER\", \"EMPLOYER_ORGANIZATION_TYPE\", \"CURRENCY\" (en ambas tablas).\n",
    "\n",
    "- Categóricas numéricas: \"NON_COMPLIANT_CONTRACT\", \"DIGITAL_CLIENT\".\n",
    "\n",
    "- Fecha: \"DATE\" (sólo en behavioural).\n",
    "\n",
    "- Identificadores: \"CLIENT_ID\" (en ambas tablas), \"CONTRACT_ID\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b5a9860",
   "metadata": {},
   "source": [
    "Analizamos las filas duplicadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "1152ca68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACIÓN DE DUPLICADOS: CLIENTS\n",
      " \n",
      "• Total filas:      162977\n",
      "• Filas únicas:     162977\n",
      "• Duplicados:       0\n",
      "\n",
      "Limpio. No existen filas duplicadas exactas.\n",
      "VERIFICACIÓN DE DUPLICADOS: BEHAVIOURAL\n",
      " \n",
      "• Total filas:      1724854\n",
      "• Filas únicas:     1724854\n",
      "• Duplicados:       0\n",
      "\n",
      "Limpio. No existen filas duplicadas exactas.\n"
     ]
    }
   ],
   "source": [
    "def auditar_duplicados_completo(df, nombre_tabla):\n",
    "    print(f\"VERIFICACIÓN DE DUPLICADOS: {nombre_tabla}\\n \")\n",
    "    \n",
    "    # 1. Cálculos Básicos\n",
    "    total_rows = df.count()\n",
    "    distinct_rows = df.distinct().count()\n",
    "    num_duplicados = total_rows - distinct_rows\n",
    "    \n",
    "    print(f\"• Total filas:      {total_rows}\")\n",
    "    print(f\"• Filas únicas:     {distinct_rows}\")\n",
    "    print(f\"• Duplicados:       {num_duplicados}\")\n",
    "    \n",
    "    # 2. Lógica Condicional\n",
    "    if num_duplicados > 0:\n",
    "        pct = (num_duplicados / total_rows) * 100\n",
    "        print(f\"\\n AVISO: Hay {num_duplicados} filas repetidas ({pct:.2f}%).\")\n",
    "        print(\"   Mostrando ejemplos de filas idénticas:\")\n",
    "        \n",
    "        # Esta parte solo se ejecuta si hay duplicados \n",
    "        # Agrupamos por TODAS las columnas para encontrar filas 100% idénticas\n",
    "        (df.groupBy(df.columns)\n",
    "           .count()\n",
    "           .where(F.col(\"count\") > 1)\n",
    "           .orderBy(F.col(\"count\").desc()) # Ponemos las más repetidas arriba\n",
    "           .show(5, truncate=False))\n",
    "        \n",
    "    else:\n",
    "        print(\"\\nLimpio. No existen filas duplicadas exactas.\")\n",
    "        \n",
    "\n",
    "# --- EJECUCIÓN ---\n",
    "auditar_duplicados_completo(df_clients, \"CLIENTS\")\n",
    "auditar_duplicados_completo(df_behav, \"BEHAVIOURAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43b78be5",
   "metadata": {},
   "source": [
    "Ahora analizamos los posibles IDs duplicados"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8e0f7a29",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VERIFICACIÓN DE CLAVE ÚNICA (CLIENT_ID): CLIENTS\n",
      " \n",
      "CORRECTO: La columna CLIENT_ID es una clave primaria única.\n"
     ]
    }
   ],
   "source": [
    "def auditar_clave_primaria(df, col_id, nombre_tabla):\n",
    "    print(f\"VERIFICACIÓN DE CLAVE ÚNICA ({col_id}): {nombre_tabla}\\n \")\n",
    "    \n",
    "    # 1. Contamos filas totales\n",
    "    total = df.count()\n",
    "    \n",
    "    # 2. Contamos IDs únicos\n",
    "    unicos = df.select(col_id).distinct().count()\n",
    "    \n",
    "    # 3. Diferencia\n",
    "    dif = total - unicos\n",
    "    \n",
    "    if dif > 0:\n",
    "        print(f\"AVISO: Hay {dif} IDs repetidos que NO son filas idénticas.\")\n",
    "        print(\"   Esto significa que tienes clientes con datos conflictivos.\")\n",
    "        print(\"   Ejemplo de IDs repetidos:\")\n",
    "        \n",
    "        # Mostramos cuáles son los culpables\n",
    "        (df.groupBy(col_id)\n",
    "           .count()\n",
    "           .where(F.col(\"count\") > 1)\n",
    "           .show(5))\n",
    "    else:\n",
    "        print(f\"CORRECTO: La columna {col_id} es una clave primaria única.\")\n",
    "\n",
    "# Ejecutamos solo para CLIENTS\n",
    "auditar_clave_primaria(df_clients, \"CLIENT_ID\", \"CLIENTS\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "44b787f3",
   "metadata": {},
   "source": [
    "Como vemos que no hay duplicados, no es necesario hacer limpieza de estos. Nos enfocaremos en los NaNs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa06436e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECCIÓN DE: CLIENTS\n",
      "\n",
      "Dimensiones: 162977 filas x 45 columnas\n",
      "\n",
      "--- 1. Conteo de Nulos ---\n",
      "-RECORD 0-----------------------------\n",
      " CLIENT_ID                   | 0      \n",
      " NON_COMPLIANT_CONTRACT      | 0      \n",
      " NAME_PRODUCT_TYPE           | 0      \n",
      " GENDER                      | 0      \n",
      " TOTAL_INCOME                | 0      \n",
      " AMOUNT_PRODUCT              | 0      \n",
      " INSTALLMENT                 | 7      \n",
      " EDUCATION                   | 39640  \n",
      " MARITAL_STATUS              | 2      \n",
      " HOME_SITUATION              | 0      \n",
      " REGION_SCORE                | 0      \n",
      " AGE_IN_YEARS                | 0      \n",
      " JOB_SENIORITY               | 29174  \n",
      " HOME_SENIORITY              | 0      \n",
      " LAST_UPDATE                 | 0      \n",
      " OWN_INSURANCE_CAR           | 0      \n",
      " CAR_AGE                     | 107550 \n",
      " FAMILY_SIZE                 | 2      \n",
      " REACTIVE_SCORING            | 91901  \n",
      " PROACTIVE_SCORING           | 337    \n",
      " BEHAVIORAL_SCORING          | 32246  \n",
      " DAYS_LAST_INFO_CHANGE       | 1      \n",
      " NUMBER_OF_PRODUCTS          | 21903  \n",
      " OCCUPATION                  | 0      \n",
      " DIGITAL_CLIENT              | 0      \n",
      " HOME_OWNER                  | 0      \n",
      " EMPLOYER_ORGANIZATION_TYPE  | 29464  \n",
      " CURRENCY                    | 0      \n",
      " NUM_PREVIOUS_LOAN_APP       | 8770   \n",
      " LOAN_ANNUITY_PAYMENT_MAX    | 8770   \n",
      " LOAN_ANNUITY_PAYMENT_MIN    | 8770   \n",
      " LOAN_ANNUITY_PAYMENT_SUM    | 8770   \n",
      " LOAN_APPLICATION_AMOUNT_MAX | 8770   \n",
      " LOAN_APPLICATION_AMOUNT_MIN | 8770   \n",
      " LOAN_APPLICATION_AMOUNT_SUM | 8770   \n",
      " LOAN_CREDIT_GRANTED_MAX     | 8770   \n",
      " LOAN_CREDIT_GRANTED_MIN     | 8770   \n",
      " LOAN_CREDIT_GRANTED_SUM     | 8770   \n",
      " LOAN_VARIABLE_RATE_MAX      | 8770   \n",
      " LOAN_VARIABLE_RATE_MIN      | 8770   \n",
      " NUM_STATUS_ANNULLED         | 8770   \n",
      " NUM_STATUS_AUTHORIZED       | 8770   \n",
      " NUM_STATUS_DENIED           | 8770   \n",
      " NUM_STATUS_NOT_USED         | 8770   \n",
      " NUM_FLAG_INSURED            | 8770   \n",
      "\n",
      "INSPECCIÓN DE: BEHAVIOURAL\n",
      "\n",
      "Dimensiones: 1724854 filas x 14 columnas\n",
      "\n",
      "--- 1. Conteo de Nulos ---\n",
      "-RECORD 0-------------------------\n",
      " CONTRACT_ID                | 0   \n",
      " CLIENT_ID                  | 0   \n",
      " DATE                       | 0   \n",
      " CREDICT_CARD_BALANCE       | 0   \n",
      " CREDIT_CARD_LIMIT          | 0   \n",
      " CREDIT_CARD_DRAWINGS_ATM   | 0   \n",
      " CREDIT_CARD_DRAWINGS       | 0   \n",
      " CREDIT_CARD_DRAWINGS_POS   | 0   \n",
      " CREDIT_CARD_DRAWINGS_OTHER | 0   \n",
      " CREDIT_CARD_PAYMENT        | 0   \n",
      " NUMBER_DRAWINGS_ATM        | 0   \n",
      " NUMBER_DRAWINGS            | 0   \n",
      " NUMBER_INSTALMENTS         | 0   \n",
      " CURRENCY                   | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "# 1. Definimos la función mejorada (le añadimos un título para que quede claro)\n",
    "def inspeccionar_datos(df, nombre_tabla):\n",
    "    \n",
    "    print(f\"INSPECCIÓN DE: {nombre_tabla}\\n\")\n",
    "    \n",
    "    print(f\"Dimensiones: {df.count()} filas x {len(df.columns)} columnas\")\n",
    "    \n",
    "    print(f\"\\n--- 1. Conteo de Nulos ---\")\n",
    "    # Calculamos nulos\n",
    "    exprs_nulos = [F.count(F.when(F.col(c).isNull(), c)).alias(c) for c in df.columns]\n",
    "    # Mostramos verticalmente para leer mejor\n",
    "    df.agg(*exprs_nulos).show(vertical=True, truncate=False)\n",
    "\n",
    "# 2. Ejecutamos la inspección (SIN meterlo dentro de otro print)\n",
    "inspeccionar_datos(df_clients, \"CLIENTS\")\n",
    "inspeccionar_datos(df_behav, \"BEHAVIOURAL\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "40c995d4",
   "metadata": {},
   "source": [
    "Se observa que solamente tendremos que tratar nulls de la tabla de clientes. Pero además, no nos interesa eliminar filas porque eliminaríamos clientes, y menos en variables con tantos nulls como CAR_AGE, donde estaríamos eliminando más del 66% de los clientes. La estrategia ganadora en Big Data es \"Imputar lo masivo, borrar lo anecdótico\"."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3aba9c20",
   "metadata": {},
   "source": [
    "Primero de todo, eliminaremos a los clientes que no proporcionen casi datos, pues prácticamente es como si no existiese."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2dcee95d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Filas antes de limpieza fina: 162977\n",
      "Filas tras limpieza fina: 161078\n"
     ]
    }
   ],
   "source": [
    "# ELIMINAR \"CLIENTES ZOMBIE\" (Filas con demasiados nulos)\n",
    "\n",
    "print(f\"Filas antes de limpieza fina: {df_clients.count()}\")\n",
    "\n",
    "# Tenemos unas 45 columnas. Si a un cliente le faltan más de 20 datos, no nos sirve.\n",
    "# thresh=25 significa: \"Mantener solo si tiene al menos 25 columnas con datos válidos\"\n",
    "df_clients = df_clients.dropna(thresh=25) \n",
    "\n",
    "print(f\"Filas tras limpieza fina: {df_clients.count()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b57614f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. LIMPIEZA Y TRANSFORMACIÓN\n",
    "\n",
    "# A) LIMPIEZA DE STRINGS (CLIENTS)\n",
    "# Lista de tus columnas categóricas reales (copiadas de tu esquema)\n",
    "cols_categ_puras = [\n",
    "    \"NAME_PRODUCT_TYPE\", \"GENDER\", \"EDUCATION\", \"MARITAL_STATUS\", \n",
    "    \"HOME_SITUATION\", \"OWN_INSURANCE_CAR\", \"OCCUPATION\", \n",
    "    \"HOME_OWNER\", \"EMPLOYER_ORGANIZATION_TYPE\", \"CURRENCY\"\n",
    "]\n",
    "\n",
    "# Normalizamos: quitamos espacios (trim) y pasamos a mayúsculas o minúsculas\n",
    "for col_name in cols_categ_puras:\n",
    "    # Solo si la columna existe en el dataframe\n",
    "    if col_name in df_clients.columns:\n",
    "        df_clients = df_clients.withColumn(col_name, F.trim(F.upper(F.col(col_name))))\n",
    "\n",
    "# B) CONVERSIÓN DE FECHAS (BEHAVIOURAL)\n",
    "# Tu columna DATE es string, hay que pasarla a formato fecha\n",
    "# Spark suele ser listo, pero si falla, prueba con formato específico ej: \"dd/MM/yyyy\"\n",
    "df_behav = df_behav.withColumn(\"DATE\", F.to_date(F.col(\"DATE\")))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "cf81f123",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Limpieza completada.\n"
     ]
    }
   ],
   "source": [
    "# C) LIMPIEZA DE NULOS \n",
    "\n",
    "# 1. GRUPO \"NO APLICA\" (Rellenar con -1)\n",
    "# Variables donde Nulo significa \"No tiene\" o \"No disponible\"\n",
    "# CAR_AGE (66% nulos), JOB_SENIORITY, SCORING...\n",
    "cols_flag = [\"CAR_AGE\", \"JOB_SENIORITY\", \"REACTIVE_SCORING\", \"BEHAVIORAL_SCORING\", \"PROACTIVE_SCORING\"]\n",
    "df_clients = df_clients.fillna(-1, subset=cols_flag)\n",
    "\n",
    "# 2. GRUPO \"SIN HISTORIAL\" (Rellenar con 0)\n",
    "# El grupo de los 8770 nulos. Si no hay datos de préstamos, asumimos 0.\n",
    "# Buscamos todas las columnas de préstamos (LOAN_) y estados (NUM_STATUS_)\n",
    "cols_financieras = [c for c in df_clients.columns if c.startswith(\"LOAN_\") or c.startswith(\"NUM_\")]\n",
    "# Añadimos otras que tengan sentido ser 0\n",
    "cols_financieras.extend([\"NUM_PREVIOUS_LOAN_APP\", \"NUMBER_OF_PRODUCTS\", \"Num_flag_insured\"]) # Asegúrate de usar el nombre exacto (mayusc/minusc)\n",
    "\n",
    "# Filtramos solo las que existen en el DF para no dar error\n",
    "cols_financieras = [c for c in cols_financieras if c in df_clients.columns]\n",
    "df_clients = df_clients.fillna(0, subset=cols_financieras)\n",
    "\n",
    "# 3. GRUPO \"CATEGÓRICO DESCONOCIDO\" (Rellenar con 'Unknown')\n",
    "# EDUCATION tiene 39k nulos. No podemos inventárnosla.\n",
    "cols_categ_nulos = [\"EDUCATION\", \"EMPLOYER_ORGANIZATION_TYPE\"]\n",
    "df_clients = df_clients.fillna(\"UNKNOWN\", subset=cols_categ_nulos)\n",
    "\n",
    "# 4. GRUPO \"ANECDÓTICO\" (Estrategia: Salvar al Cliente)\n",
    "# Al ser poquísimos nulos, preferimos imputar para no perder la ficha del cliente.\n",
    "\n",
    "# A) Para Numéricas (Installment): Usamos la MEDIANA (más robusta que la media)\n",
    "# Calculamos la mediana aproximada (approxQuantile es muy eficiente en Spark)\n",
    "mediana_inst = df_clients.stat.approxQuantile(\"INSTALLMENT\", [0.5], 0.01)[0]\n",
    "df_clients = df_clients.fillna(mediana_inst, subset=[\"INSTALLMENT\"])\n",
    "\n",
    "# B) Para Categóricas (Marital Status, Family Size): Usamos \"UNKNOWN\"\n",
    "# Usar la moda requeriría más código, y para 2 filas no merece la pena el coste computacional.\n",
    "# \"UNKNOWN\" nos permite ver en el Dashboard si hay errores de calidad.\n",
    "cols_anecdoticas = [\"MARITAL_STATUS\", \"FAMILY_SIZE\"]\n",
    "df_clients = df_clients.fillna(\"UNKNOWN\", subset=cols_anecdoticas)\n",
    "\n",
    "print(\"Limpieza completada.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c72a266f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INSPECCIÓN DE: CLIENTS\n",
      "\n",
      "Dimensiones: 161078 filas x 45 columnas\n",
      "\n",
      "--- 1. Conteo de Nulos ---\n",
      "-RECORD 0--------------------------\n",
      " CLIENT_ID                   | 0   \n",
      " NON_COMPLIANT_CONTRACT      | 0   \n",
      " NAME_PRODUCT_TYPE           | 0   \n",
      " GENDER                      | 0   \n",
      " TOTAL_INCOME                | 0   \n",
      " AMOUNT_PRODUCT              | 0   \n",
      " INSTALLMENT                 | 0   \n",
      " EDUCATION                   | 0   \n",
      " MARITAL_STATUS              | 0   \n",
      " HOME_SITUATION              | 0   \n",
      " REGION_SCORE                | 0   \n",
      " AGE_IN_YEARS                | 0   \n",
      " JOB_SENIORITY               | 0   \n",
      " HOME_SENIORITY              | 0   \n",
      " LAST_UPDATE                 | 0   \n",
      " OWN_INSURANCE_CAR           | 0   \n",
      " CAR_AGE                     | 0   \n",
      " FAMILY_SIZE                 | 0   \n",
      " REACTIVE_SCORING            | 0   \n",
      " PROACTIVE_SCORING           | 0   \n",
      " BEHAVIORAL_SCORING          | 0   \n",
      " DAYS_LAST_INFO_CHANGE       | 0   \n",
      " NUMBER_OF_PRODUCTS          | 0   \n",
      " OCCUPATION                  | 0   \n",
      " DIGITAL_CLIENT              | 0   \n",
      " HOME_OWNER                  | 0   \n",
      " EMPLOYER_ORGANIZATION_TYPE  | 0   \n",
      " CURRENCY                    | 0   \n",
      " NUM_PREVIOUS_LOAN_APP       | 0   \n",
      " LOAN_ANNUITY_PAYMENT_MAX    | 0   \n",
      " LOAN_ANNUITY_PAYMENT_MIN    | 0   \n",
      " LOAN_ANNUITY_PAYMENT_SUM    | 0   \n",
      " LOAN_APPLICATION_AMOUNT_MAX | 0   \n",
      " LOAN_APPLICATION_AMOUNT_MIN | 0   \n",
      " LOAN_APPLICATION_AMOUNT_SUM | 0   \n",
      " LOAN_CREDIT_GRANTED_MAX     | 0   \n",
      " LOAN_CREDIT_GRANTED_MIN     | 0   \n",
      " LOAN_CREDIT_GRANTED_SUM     | 0   \n",
      " LOAN_VARIABLE_RATE_MAX      | 0   \n",
      " LOAN_VARIABLE_RATE_MIN      | 0   \n",
      " NUM_STATUS_ANNULLED         | 0   \n",
      " NUM_STATUS_AUTHORIZED       | 0   \n",
      " NUM_STATUS_DENIED           | 0   \n",
      " NUM_STATUS_NOT_USED         | 0   \n",
      " NUM_FLAG_INSURED            | 0   \n",
      "\n"
     ]
    }
   ],
   "source": [
    "inspeccionar_datos(df_clients, \"CLIENTS\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "74c42e45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " FASE 1: JOIN Y DIAGNÓSTICO (NOMBRES ORIGINALES)\n",
      "\n",
      "Uniendo tablas por CLIENT_ID...\n",
      "CORRECTO: 1 Cliente = 1 Fila.\n",
      " ESTADO ACTUAL (PRE-REDUCCIÓN)\n",
      "\n",
      "Dimensiones: 161078 filas x 58 columnas\n",
      "\n",
      "Esquema Actual \n",
      "root\n",
      " |-- CLIENT_ID: string (nullable = true)\n",
      " |-- NON_COMPLIANT_CONTRACT: integer (nullable = true)\n",
      " |-- NAME_PRODUCT_TYPE: string (nullable = true)\n",
      " |-- GENDER: string (nullable = true)\n",
      " |-- TOTAL_INCOME: double (nullable = true)\n",
      " |-- AMOUNT_PRODUCT: double (nullable = true)\n",
      " |-- INSTALLMENT: double (nullable = false)\n",
      " |-- EDUCATION: string (nullable = false)\n",
      " |-- MARITAL_STATUS: string (nullable = false)\n",
      " |-- HOME_SITUATION: string (nullable = true)\n",
      " |-- REGION_SCORE: double (nullable = true)\n",
      " |-- AGE_IN_YEARS: double (nullable = true)\n",
      " |-- JOB_SENIORITY: double (nullable = false)\n",
      " |-- HOME_SENIORITY: double (nullable = true)\n",
      " |-- LAST_UPDATE: double (nullable = true)\n",
      " |-- OWN_INSURANCE_CAR: string (nullable = true)\n",
      " |-- CAR_AGE: double (nullable = false)\n",
      " |-- FAMILY_SIZE: double (nullable = true)\n",
      " |-- REACTIVE_SCORING: double (nullable = false)\n",
      " |-- PROACTIVE_SCORING: double (nullable = false)\n",
      " |-- BEHAVIORAL_SCORING: double (nullable = false)\n",
      " |-- DAYS_LAST_INFO_CHANGE: double (nullable = true)\n",
      " |-- NUMBER_OF_PRODUCTS: double (nullable = false)\n",
      " |-- OCCUPATION: string (nullable = true)\n",
      " |-- DIGITAL_CLIENT: integer (nullable = true)\n",
      " |-- HOME_OWNER: string (nullable = true)\n",
      " |-- EMPLOYER_ORGANIZATION_TYPE: string (nullable = false)\n",
      " |-- CURRENCY: string (nullable = true)\n",
      " |-- NUM_PREVIOUS_LOAN_APP: double (nullable = false)\n",
      " |-- LOAN_ANNUITY_PAYMENT_MAX: double (nullable = false)\n",
      " |-- LOAN_ANNUITY_PAYMENT_MIN: double (nullable = false)\n",
      " |-- LOAN_ANNUITY_PAYMENT_SUM: double (nullable = false)\n",
      " |-- LOAN_APPLICATION_AMOUNT_MAX: double (nullable = false)\n",
      " |-- LOAN_APPLICATION_AMOUNT_MIN: double (nullable = false)\n",
      " |-- LOAN_APPLICATION_AMOUNT_SUM: double (nullable = false)\n",
      " |-- LOAN_CREDIT_GRANTED_MAX: double (nullable = false)\n",
      " |-- LOAN_CREDIT_GRANTED_MIN: double (nullable = false)\n",
      " |-- LOAN_CREDIT_GRANTED_SUM: double (nullable = false)\n",
      " |-- LOAN_VARIABLE_RATE_MAX: double (nullable = false)\n",
      " |-- LOAN_VARIABLE_RATE_MIN: double (nullable = false)\n",
      " |-- NUM_STATUS_ANNULLED: double (nullable = false)\n",
      " |-- NUM_STATUS_AUTHORIZED: double (nullable = false)\n",
      " |-- NUM_STATUS_DENIED: double (nullable = false)\n",
      " |-- NUM_STATUS_NOT_USED: double (nullable = false)\n",
      " |-- NUM_FLAG_INSURED: double (nullable = false)\n",
      " |-- CONTRACT_ID: string (nullable = true)\n",
      " |-- DATE: date (nullable = true)\n",
      " |-- CREDICT_CARD_BALANCE: double (nullable = false)\n",
      " |-- CREDIT_CARD_LIMIT: double (nullable = false)\n",
      " |-- CREDIT_CARD_DRAWINGS_ATM: double (nullable = false)\n",
      " |-- CREDIT_CARD_DRAWINGS: double (nullable = false)\n",
      " |-- CREDIT_CARD_DRAWINGS_POS: double (nullable = false)\n",
      " |-- CREDIT_CARD_DRAWINGS_OTHER: double (nullable = false)\n",
      " |-- CREDIT_CARD_PAYMENT: double (nullable = false)\n",
      " |-- NUMBER_DRAWINGS_ATM: double (nullable = true)\n",
      " |-- NUMBER_DRAWINGS: long (nullable = true)\n",
      " |-- NUMBER_INSTALMENTS: double (nullable = true)\n",
      " |-- CURRENCY: string (nullable = true)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 5. INTEGRACIÓN (JOIN) - MODO NOMBRES ORIGINALES\n",
    "\n",
    "\n",
    "print(\" FASE 1: JOIN Y DIAGNÓSTICO (NOMBRES ORIGINALES)\\n\")\n",
    "\n",
    "col_id = \"CLIENT_ID\" \n",
    "\n",
    "# --- A. SNAPSHOT (Último dato por cliente) ---\n",
    "df_behav = df_behav.withColumn(\"DATE\", F.to_date(F.col(\"DATE\")))\n",
    "\n",
    "# Ventana para quedarnos con el último registro\n",
    "w = Window.partitionBy(col_id).orderBy(F.desc(\"DATE\"))\n",
    "df_behav_dedup = df_behav.withColumn(\"rank\", F.row_number().over(w)) \\\n",
    "                         .filter(F.col(\"rank\") == 1) \\\n",
    "                         .drop(\"rank\")\n",
    "\n",
    "# --- B. JOIN ---\n",
    "print(f\"Uniendo tablas por {col_id}...\")\n",
    "df_master = df_clients.join(df_behav_dedup, on=col_id, how=\"left\")\n",
    "\n",
    "# --- C. INTEGRIDAD ---\n",
    "filas_clientes = df_clients.count()\n",
    "filas_master = df_master.count()\n",
    "\n",
    "if filas_master > filas_clientes:\n",
    "    diff = filas_master - filas_clientes\n",
    "    print(f\"AVISO: Aún hay {diff} duplicados.\")\n",
    "else:\n",
    "    print(f\"CORRECTO: 1 Cliente = 1 Fila.\")\n",
    "\n",
    "# --- D. LIMPIEZA POST-JOIN (Nulos a 0) ---\n",
    "# Tras el join, las columnas financieras de BEHAVIOURAL pueden tener nulos\n",
    "cols_financieras = [\n",
    "    \"CREDICT_CARD_BALANCE\", \"CREDIT_CARD_LIMIT\", \"NUMBER_DRAWINGS\", \n",
    "    \"CREDIT_CARD_DRAWINGS_ATM\", \"CREDIT_CARD_DRAWINGS_POS\", \n",
    "    \"CREDIT_CARD_DRAWINGS_OTHER\", \"CREDIT_CARD_DRAWINGS\", \"CREDIT_CARD_PAYMENT\"\n",
    "]\n",
    "\n",
    "cols_existentes = [c for c in cols_financieras if c in df_master.columns]\n",
    "df_master = df_master.fillna(0, subset=cols_existentes)\n",
    "\n",
    "# E. INFORMACIÓN DE LA TABLA \n",
    "print(\" ESTADO ACTUAL (PRE-REDUCCIÓN)\\n\")\n",
    "print(f\"Dimensiones: {df_master.count()} filas x {len(df_master.columns)} columnas\")\n",
    "print(\"\\nEsquema Actual \")\n",
    "df_master.printSchema()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "214d0491",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "FASE 2: KPIs AVANZADOS Y LIMPIEZA FINAL\n",
      " \n",
      "Generando KPIs estratégicos...\n",
      "Eliminando columnas redundantes e inútiles...\n",
      "ESTADO FINAL OPTIMIZADO\n",
      "\n",
      "Dimensiones: 161078 filas x 49 columnas\n",
      "(Se han eliminado 14 columnas redundantes y creado 6 KPIs estratégicos)\n",
      "\n",
      "Guardado archivo en: /home/jovyan/work/data/curated/Master_FinPlus.parquet.\n",
      "\n",
      "Guardado.\n",
      " Ruta: /home/jovyan/work/data/curated/Master_FinPlus_Final.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# 6. FEATURE ENGINEERING Y REDUCCIÓN FINAL\n",
    "\n",
    "print(\"FASE 2: KPIs AVANZADOS Y LIMPIEZA FINAL\\n \")\n",
    "\n",
    "# --- A. CREACIÓN DE KPIs (Información de Negocio) ---\n",
    "print(\"Generando KPIs estratégicos...\")\n",
    "\n",
    "# 1. KPI Gasto Total Tarjeta (Suma de los parciales)\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_TOTAL_SPEND\",\n",
    "    F.col(\"CREDIT_CARD_DRAWINGS_ATM\") + F.col(\"CREDIT_CARD_DRAWINGS_POS\") + F.col(\"CREDIT_CARD_DRAWINGS_OTHER\")\n",
    ")\n",
    "\n",
    "# 2. KPI Ratio Endeudamiento (Deuda / Ingresos)\n",
    "# Sumamos 1 al ingreso para evitar divisiones por cero\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_DEBT_RATIO\",\n",
    "    F.round(F.col(\"CREDICT_CARD_BALANCE\") / (F.col(\"TOTAL_INCOME\") + 1), 4)\n",
    ")\n",
    "\n",
    "# 3. KPI Grupo de Edad (Simplificación demográfica)\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_AGE_GROUP\",\n",
    "    F.when(F.col(\"AGE_IN_YEARS\") < 30, \"Joven\")\n",
    "     .when(F.col(\"AGE_IN_YEARS\") < 50, \"Adulto\")\n",
    "     .otherwise(\"Senior\")\n",
    ")\n",
    "\n",
    "# 4. KPI Volatilidad de Préstamos (Max - Min)\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_LOAN_VOLATILITY\",\n",
    "    F.col(\"LOAN_CREDIT_GRANTED_MAX\") - F.col(\"LOAN_CREDIT_GRANTED_MIN\")\n",
    ")\n",
    "\n",
    "# 5. KPI Ratio de Aprobación (Lo que le dieron / Lo que pidió)\n",
    "# Indica la confianza del banco en el cliente\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_APPROVAL_RATIO\",\n",
    "    F.round(F.col(\"LOAN_CREDIT_GRANTED_SUM\") / (F.col(\"LOAN_APPLICATION_AMOUNT_SUM\") + 1), 2)\n",
    ")\n",
    "\n",
    "# 6. KPI Tasa de Rechazo (Solicitudes denegadas / Total)\n",
    "# Resume los estados conflictivos\n",
    "df_master = df_master.withColumn(\n",
    "    \"KPI_DENIAL_RATE\",\n",
    "    F.round(F.col(\"NUM_STATUS_DENIED\") / \n",
    "            (F.col(\"NUM_STATUS_AUTHORIZED\") + F.col(\"NUM_STATUS_DENIED\") + F.col(\"NUM_STATUS_ANNULLED\") + 1), 2)\n",
    ")\n",
    "\n",
    "# --- B. REDUCCIÓN DE COLUMNAS (Limpieza de \"Grasa\") ---\n",
    "print(\"Eliminando columnas redundantes e inútiles...\")\n",
    "\n",
    "cols_a_borrar = [\n",
    "    # 1. Redundantes de Tarjeta (Sustituidas por KPI_TOTAL_SPEND)\n",
    "    \"CREDIT_CARD_DRAWINGS_ATM\", \"CREDIT_CARD_DRAWINGS_POS\", \"CREDIT_CARD_DRAWINGS_OTHER\", \n",
    "    \"CREDIT_CARD_DRAWINGS\", # Dato duplicado original\n",
    "    \n",
    "    # 2. Redundantes de Préstamos (Sustituidas por KPI_LOAN_VOLATILITY y APPROVAL)\n",
    "    \"LOAN_ANNUITY_PAYMENT_MAX\", \"LOAN_ANNUITY_PAYMENT_MIN\",\n",
    "    \"LOAN_APPLICATION_AMOUNT_MAX\", \"LOAN_APPLICATION_AMOUNT_MIN\",\n",
    "    \"LOAN_CREDIT_GRANTED_MAX\", \"LOAN_CREDIT_GRANTED_MIN\",\n",
    "    \"LOAN_VARIABLE_RATE_MAX\", \"LOAN_VARIABLE_RATE_MIN\",\n",
    "\n",
    "    # 3. Basura Técnica y Duplicados\n",
    "    \"CONTRACT_ID\",  # ID interno técnico (inútil para negocio)\n",
    "    \"CURRENCY\"      # Columna duplicada por el Join (borramos ambas)\n",
    "    ]\n",
    "\n",
    "# Borrado seguro (solo las que existan)\n",
    "cols_finales_borrar = [c for c in cols_a_borrar if c in df_master.columns]\n",
    "df_master = df_master.drop(*cols_finales_borrar)\n",
    "\n",
    "# --- C. DIMENSIONES FINALES ---\n",
    "\n",
    "print(\"ESTADO FINAL OPTIMIZADO\\n\")\n",
    "print(f\"Dimensiones: {df_master.count()} filas x {len(df_master.columns)} columnas\")\n",
    "print(f\"(Se han eliminado {len(cols_finales_borrar)} columnas redundantes y creado 6 KPIs estratégicos)\")\n",
    "\n",
    "# --- D. GUARDADO FINAL ---\n",
    "ruta_final = OUTPUT_PATH + \"Master_FinPlus.parquet\"\n",
    "df_master.write.mode(\"overwrite\").parquet(ruta_final)\n",
    "print(f\"\\nGuardado archivo en: {ruta_final}.\")\n",
    "\n",
    "# --- E. GUARDADO EN PARQUET ÚNICO ---\n",
    "\n",
    "df_pandas = df_master.toPandas()\n",
    "\n",
    "nombre_archivo = \"Master_FinPlus_Final.parquet\"\n",
    "ruta_completa = OUTPUT_PATH + nombre_archivo\n",
    "\n",
    "# Necesitas tener instalada la librería pyarrow o fastparquet (suele venir en Docker)\n",
    "df_pandas.to_parquet(ruta_completa, index=False)\n",
    "\n",
    "print(f\"\\nGuardado.\")\n",
    "print(f\" Ruta: {ruta_completa}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "0439fb74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " VERIFICACIÓN DE OUTLIERS (Método IQR)\n",
      "\n",
      " Columna: TOTAL_INCOME\n",
      "   Rango Normal: [-270.00  a  4050.00]\n",
      "   Outliers detectados: 7244 filas\n",
      "   Ejemplos (Top Extremos):\n",
      "+------------+\n",
      "|TOTAL_INCOME|\n",
      "+------------+\n",
      "|   1404000.0|\n",
      "|   216001.08|\n",
      "|    108000.0|\n",
      "+------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      " Columna: AGE_IN_YEARS -> Sin outliers estadísticos.\n",
      "\n",
      " Columna: AMOUNT_PRODUCT\n",
      "   Rango Normal: [-6455.70  a  19399.50]\n",
      "   Outliers detectados: 3395 filas\n",
      "   Ejemplos (Top Extremos):\n",
      "+--------------+\n",
      "|AMOUNT_PRODUCT|\n",
      "+--------------+\n",
      "|     48486.195|\n",
      "|     48486.195|\n",
      "|     48486.195|\n",
      "+--------------+\n",
      "only showing top 3 rows\n",
      "\n",
      "\n",
      " Columna: CREDICT_CARD_BALANCE\n",
      "   Rango Normal: [0.00  a  0.00]\n",
      "   Outliers detectados: 16332 filas\n",
      "   Ejemplos (Top Extremos):\n",
      "+--------------------+\n",
      "|CREDICT_CARD_BALANCE|\n",
      "+--------------------+\n",
      "|            14526.13|\n",
      "|            12122.07|\n",
      "|            11500.21|\n",
      "+--------------------+\n",
      "only showing top 3 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def auditar_outliers(df, cols_numericas):\n",
    "    \n",
    "    print(f\" VERIFICACIÓN DE OUTLIERS (Método IQR)\")\n",
    "    \n",
    "    \n",
    "    for col in cols_numericas:\n",
    "        # 1. Calculamos Cuartiles (25% y 75%)\n",
    "        quantiles = df.stat.approxQuantile(col, [0.25, 0.75], 0.01)\n",
    "        q1, q3 = quantiles[0], quantiles[1]\n",
    "        iqr = q3 - q1\n",
    "        \n",
    "        # 2. Definimos límites (Bigotes del Boxplot)\n",
    "        limite_inf = q1 - 1.5 * iqr\n",
    "        limite_sup = q3 + 1.5 * iqr\n",
    "        \n",
    "        # 3. Contamos cuántos se salen\n",
    "        outliers = df.filter((F.col(col) < limite_inf) | (F.col(col) > limite_sup))\n",
    "        num_outliers = outliers.count()\n",
    "        \n",
    "        if num_outliers > 0:\n",
    "            print(f\"\\n Columna: {col}\")\n",
    "            print(f\"   Rango Normal: [{limite_inf:.2f}  a  {limite_sup:.2f}]\")\n",
    "            print(f\"   Outliers detectados: {num_outliers} filas\")\n",
    "            \n",
    "            # Mostramos los valores más extremos para ver si son errores o VIPs\n",
    "            print(f\"   Ejemplos (Top Extremos):\")\n",
    "            outliers.select(col).orderBy(F.desc(col)).show(3)\n",
    "        else:\n",
    "            print(f\"\\n Columna: {col} -> Sin outliers estadísticos.\")\n",
    "\n",
    "# Definimos las columnas numéricas críticas para analizar\n",
    "cols_analisis = [\"TOTAL_INCOME\", \"AGE_IN_YEARS\", \"AMOUNT_PRODUCT\", \"CREDICT_CARD_BALANCE\"]\n",
    "\n",
    "# Ejecutamos\n",
    "auditar_outliers(df_master, cols_analisis)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e76b2f9f",
   "metadata": {},
   "source": [
    "# INDICADORES Y ANÁLISIS DE COMPORTAMIENTO"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9053ba90",
   "metadata": {},
   "source": [
    "### ACTIVIDAD CLIENTE"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21b0ab92",
   "metadata": {},
   "source": [
    "- Cálculo de métricas de actividad:\n",
    "    - Recencia (R)\n",
    "\n",
    "    - Frecuencia (F)\n",
    "\n",
    "    - Intensidad (I)\n",
    "\n",
    "- Ventanas de actividad (30/90/180 días)\n",
    "\n",
    "- Meses activos\n",
    "\n",
    "- Clasificación de actividad (Alta / Media / Baja)\n",
    "\n",
    "- Interpretación clara de negocio\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "dbc96c9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ==========================================\n",
    "# 1. CARGAR DATOS YA PROCESADOS\n",
    "# ==========================================\n",
    "DATA_PATH = \"/home/jovyan/work/data/\"\n",
    "\n",
    "beh = spark.read.parquet(DATA_PATH + \"BEHAVIOURAL.parquet\")\n",
    "df_master = spark.read.parquet(DATA_PATH + \"curated/Master_FinPlus.parquet\")\n",
    "\n",
    "beh = beh.withColumn(\"DATE\", F.to_date(\"DATE\", \"yyyy-MM-dd\"))\n",
    "max_date = beh.agg(F.max(\"DATE\")).first()[0]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "9dff808e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ RECENCIA (R) ================\n",
      "\n",
      "Interpretación: número de días desde la última actividad del cliente.\n",
      "+-------+------------------+\n",
      "|summary|      RECENCY_DAYS|\n",
      "+-------+------------------+\n",
      "|  count|             46046|\n",
      "|   mean|15.444794336098685|\n",
      "| stddev| 21.54619528266414|\n",
      "|    min|                 0|\n",
      "|    max|                93|\n",
      "+-------+------------------+\n",
      "\n",
      "\n",
      "--- Top 10 clientes más recientes ---\n",
      "+------------+------------------+------------+\n",
      "|CLIENT_ID   |last_activity_date|RECENCY_DAYS|\n",
      "+------------+------------------+------------+\n",
      "|ES182303796D|2021-12-31        |0           |\n",
      "|ES182245752Y|2021-12-31        |0           |\n",
      "|ES182293250V|2021-12-31        |0           |\n",
      "|ES182245476M|2021-12-31        |0           |\n",
      "|ES182112694Y|2021-12-31        |0           |\n",
      "|ES182189508S|2021-12-31        |0           |\n",
      "|ES182433571C|2021-12-31        |0           |\n",
      "|ES182232062V|2021-12-31        |0           |\n",
      "|ES182378189N|2021-12-31        |0           |\n",
      "|ES182279031S|2021-12-31        |0           |\n",
      "+------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "\n",
      "--- Top 10 clientes más abandonados ---\n",
      "+------------+------------------+------------+\n",
      "|CLIENT_ID   |last_activity_date|RECENCY_DAYS|\n",
      "+------------+------------------+------------+\n",
      "|ES182406226A|2021-09-29        |93          |\n",
      "|ES182205817D|2021-09-29        |93          |\n",
      "|ES182211003Y|2021-09-29        |93          |\n",
      "|ES182451631D|2021-09-29        |93          |\n",
      "|ES182406265H|2021-09-29        |93          |\n",
      "|ES182405527S|2021-09-29        |93          |\n",
      "|ES182211280N|2021-09-29        |93          |\n",
      "|ES182179190D|2021-09-29        |93          |\n",
      "|ES182306422P|2021-09-29        |93          |\n",
      "|ES182109223R|2021-09-29        |93          |\n",
      "+------------+------------------+------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# 2. MÉTRICAS DE ACTIVIDAD\n",
    "# ==========================================\n",
    "\n",
    "# --- RECENCIA ---\n",
    "recencia_df = beh.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.max(\"DATE\").alias(\"last_activity_date\")\n",
    ").withColumn(\n",
    "    \"RECENCY_DAYS\", F.datediff(F.lit(max_date), F.col(\"last_activity_date\"))\n",
    ")\n",
    "\n",
    "print(\"\\n================ RECENCIA (R) ================\\n\")\n",
    "print(\"Interpretación: número de días desde la última actividad del cliente.\")\n",
    "recencia_df.describe(\"RECENCY_DAYS\").show()\n",
    "\n",
    "print(\"\\n--- Top 10 clientes más recientes ---\")\n",
    "recencia_df.orderBy(F.col(\"RECENCY_DAYS\").asc()).show(10, truncate=False)\n",
    "\n",
    "print(\"\\n--- Top 10 clientes más abandonados ---\")\n",
    "recencia_df.orderBy(F.col(\"RECENCY_DAYS\").desc()).show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "9a845daf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ FRECUENCIA (F) ================\n",
      "\n",
      "Interpretación: cuántos movimientos totales ha realizado el cliente.\n",
      "+-------+-----------------+\n",
      "|summary|  FREQUENCY_COUNT|\n",
      "+-------+-----------------+\n",
      "|  count|            46046|\n",
      "|   mean|37.45936672023628|\n",
      "| stddev|33.78619079695795|\n",
      "|    min|                1|\n",
      "|    max|              192|\n",
      "+-------+-----------------+\n",
      "\n",
      "\n",
      "--- Top 10 clientes con mayor frecuencia ---\n",
      "+------------+---------------+\n",
      "|CLIENT_ID   |FREQUENCY_COUNT|\n",
      "+------------+---------------+\n",
      "|ES182186401T|192            |\n",
      "|ES182128827G|129            |\n",
      "|ES182192917N|126            |\n",
      "|ES182283225D|122            |\n",
      "|ES182378495D|122            |\n",
      "|ES182155668A|121            |\n",
      "|ES182253915Y|121            |\n",
      "|ES182146380G|121            |\n",
      "|ES182267366X|120            |\n",
      "|ES182210848C|120            |\n",
      "+------------+---------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# --- FRECUENCIA ---\n",
    "frecuencia_df = beh.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.count(\"*\").alias(\"FREQUENCY_COUNT\")\n",
    ")\n",
    "\n",
    "print(\"\\n================ FRECUENCIA (F) ================\\n\")\n",
    "print(\"Interpretación: cuántos movimientos totales ha realizado el cliente.\")\n",
    "frecuencia_df.describe(\"FREQUENCY_COUNT\").show()\n",
    "\n",
    "print(\"\\n--- Top 10 clientes con mayor frecuencia ---\")\n",
    "frecuencia_df.orderBy(F.col(\"FREQUENCY_COUNT\").desc()).show(10, truncate=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3a386cf2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ INTENSIDAD (I) ================\n",
      "\n",
      "Interpretación: gasto promedio por movimiento del cliente.\n",
      "+-------+-------------------+\n",
      "|summary|INTENSITY_AVG_SPEND|\n",
      "+-------+-------------------+\n",
      "|  count|              46046|\n",
      "|   mean| 165.34456214658363|\n",
      "| stddev|  310.5056279798483|\n",
      "|    min|                0.0|\n",
      "|    max|  9629.483333333334|\n",
      "+-------+-------------------+\n",
      "\n",
      "\n",
      "--- Top 10 clientes con mayor intensidad ---\n",
      "+------------+-------------------+\n",
      "|CLIENT_ID   |INTENSITY_AVG_SPEND|\n",
      "+------------+-------------------+\n",
      "|ES182227107Z|9629.483333333334  |\n",
      "|ES182354235A|8642.13            |\n",
      "|ES182436756T|7395.070000000001  |\n",
      "|ES182156500S|5901.773846153846  |\n",
      "|ES182366160A|5899.592142857144  |\n",
      "|ES182390308Q|5731.825           |\n",
      "|ES182247132U|5427.0             |\n",
      "|ES182396618L|5346.0             |\n",
      "|ES182129030R|5245.332173913043  |\n",
      "|ES182250483A|5186.4158333333335 |\n",
      "+------------+-------------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# --- INTENSIDAD ---\n",
    "beh = beh.withColumn(\n",
    "    \"KPI_TOTAL_SPEND\",\n",
    "    F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_ATM\"), F.lit(0)) +\n",
    "    F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_POS\"), F.lit(0)) +\n",
    "    F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_OTHER\"), F.lit(0))\n",
    ")\n",
    "\n",
    "intensidad_df = beh.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.avg(\"KPI_TOTAL_SPEND\").alias(\"INTENSITY_AVG_SPEND\")\n",
    ")\n",
    "\n",
    "print(\"\\n================ INTENSIDAD (I) ================\\n\")\n",
    "print(\"Interpretación: gasto promedio por movimiento del cliente.\")\n",
    "intensidad_df.describe(\"INTENSITY_AVG_SPEND\").show()\n",
    "\n",
    "print(\"\\n--- Top 10 clientes con mayor intensidad ---\")\n",
    "intensidad_df.orderBy(F.col(\"INTENSITY_AVG_SPEND\").desc()).show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "af8361f8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ ACTIVIDAD EN VENTANAS ================\n",
      "\n",
      "Interpretación: cuántas interacciones ha tenido el cliente en los últimos X días.\n",
      "\n",
      "--- Top 10 actividad últimos 30 días ---\n",
      "+------------+------------+------------+-------------+\n",
      "|CLIENT_ID   |ACTIVITY_30D|ACTIVITY_90D|ACTIVITY_180D|\n",
      "+------------+------------+------------+-------------+\n",
      "|ES182403907W|2           |6           |12           |\n",
      "|ES182334710B|2           |6           |12           |\n",
      "|ES182210848C|2           |6           |12           |\n",
      "|ES182347896Q|2           |6           |12           |\n",
      "|ES182243027C|2           |6           |11           |\n",
      "|ES182407401Q|2           |6           |12           |\n",
      "|ES182127891W|2           |5           |8            |\n",
      "|ES182150696Z|2           |6           |12           |\n",
      "|ES182100594F|2           |4           |7            |\n",
      "|ES182283225D|2           |6           |12           |\n",
      "+------------+------------+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "--- Top 10 actividad últimos 90 días ---\n",
      "+------------+------------+------------+-------------+\n",
      "|CLIENT_ID   |ACTIVITY_30D|ACTIVITY_90D|ACTIVITY_180D|\n",
      "+------------+------------+------------+-------------+\n",
      "|ES182425933U|2           |6           |12           |\n",
      "|ES182251358N|2           |6           |10           |\n",
      "|ES182334710B|2           |6           |12           |\n",
      "|ES182403907W|2           |6           |12           |\n",
      "|ES182300727X|2           |6           |12           |\n",
      "|ES182347896Q|2           |6           |12           |\n",
      "|ES182139528A|2           |6           |12           |\n",
      "|ES182407401Q|2           |6           |12           |\n",
      "|ES182212183S|2           |6           |12           |\n",
      "|ES182150696Z|2           |6           |12           |\n",
      "+------------+------------+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n",
      "--- Top 10 actividad últimos 180 días ---\n",
      "+------------+------------+------------+-------------+\n",
      "|CLIENT_ID   |ACTIVITY_30D|ACTIVITY_90D|ACTIVITY_180D|\n",
      "+------------+------------+------------+-------------+\n",
      "|ES182212183S|2           |6           |12           |\n",
      "|ES182291091W|2           |6           |12           |\n",
      "|ES182217001J|2           |6           |12           |\n",
      "|ES182403907W|2           |6           |12           |\n",
      "|ES182311871L|2           |6           |12           |\n",
      "|ES182347896Q|2           |6           |12           |\n",
      "|ES182211607S|2           |6           |12           |\n",
      "|ES182407401Q|2           |6           |12           |\n",
      "|ES182118190I|2           |6           |12           |\n",
      "|ES182425933U|2           |6           |12           |\n",
      "+------------+------------+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 3. ACTIVIDAD 30 / 90 / 180 DÍAS\n",
    "# ==========================================\n",
    "beh_windows = beh.withColumn(\n",
    "    \"DAYS_FROM_REF\", F.datediff(F.lit(max_date), F.col(\"DATE\"))\n",
    ")\n",
    "\n",
    "ventanas_df = beh_windows.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.sum(F.when(F.col(\"DAYS_FROM_REF\") <= 30, 1).otherwise(0)).alias(\"ACTIVITY_30D\"),\n",
    "    F.sum(F.when(F.col(\"DAYS_FROM_REF\") <= 90, 1).otherwise(0)).alias(\"ACTIVITY_90D\"),\n",
    "    F.sum(F.when(F.col(\"DAYS_FROM_REF\") <= 180, 1).otherwise(0)).alias(\"ACTIVITY_180D\")\n",
    ")\n",
    "\n",
    "print(\"\\n================ ACTIVIDAD EN VENTANAS ================\\n\")\n",
    "print(\"Interpretación: cuántas interacciones ha tenido el cliente en los últimos X días.\\n\")\n",
    "\n",
    "print(\"--- Top 10 actividad últimos 30 días ---\")\n",
    "ventanas_df.orderBy(F.col(\"ACTIVITY_30D\").desc()).show(10, truncate=False)\n",
    "\n",
    "print(\"--- Top 10 actividad últimos 90 días ---\")\n",
    "ventanas_df.orderBy(F.col(\"ACTIVITY_90D\").desc()).show(10, truncate=False)\n",
    "\n",
    "print(\"--- Top 10 actividad últimos 180 días ---\")\n",
    "ventanas_df.orderBy(F.col(\"ACTIVITY_180D\").desc()).show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "fded75fc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ MESES ACTIVOS ================\n",
      "\n",
      "+------------+-------------+\n",
      "|CLIENT_ID   |ACTIVE_MONTHS|\n",
      "+------------+-------------+\n",
      "|ES182319130A|96           |\n",
      "|ES182173222Z|96           |\n",
      "|ES182384509S|96           |\n",
      "|ES182167286W|96           |\n",
      "|ES182243311L|96           |\n",
      "|ES182233737B|96           |\n",
      "|ES182254666P|96           |\n",
      "|ES182258895P|96           |\n",
      "|ES182454817C|96           |\n",
      "|ES182350305O|96           |\n",
      "+------------+-------------+\n",
      "only showing top 10 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 4. MESES ACTIVOS\n",
    "# ==========================================\n",
    "beh_month = beh.withColumn(\n",
    "    \"YEAR_MONTH\", F.date_format(\"DATE\", \"yyyy-MM\")\n",
    ")\n",
    "\n",
    "meses_activos_df = beh_month.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.countDistinct(\"YEAR_MONTH\").alias(\"ACTIVE_MONTHS\")\n",
    ")\n",
    "\n",
    "print(\"\\n================ MESES ACTIVOS ================\\n\")\n",
    "meses_activos_df.orderBy(F.col(\"ACTIVE_MONTHS\").desc()).show(10, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8aaf83b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 5. COMBINAR TODAS LAS MÉTRICAS\n",
    "# ==========================================\n",
    "activity_metrics = (\n",
    "    recencia_df\n",
    "    .join(frecuencia_df, \"CLIENT_ID\", \"left\")\n",
    "    .join(intensidad_df, \"CLIENT_ID\", \"left\")\n",
    "    .join(ventanas_df, \"CLIENT_ID\", \"left\")\n",
    "    .join(meses_activos_df, \"CLIENT_ID\", \"left\")\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "d67db52f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================ SEGMENTACIÓN FINAL ================\n",
      "\n",
      "+----------------+-----+\n",
      "|ACTIVITY_SEGMENT|count|\n",
      "+----------------+-----+\n",
      "|            Alta|26002|\n",
      "|           Media|18448|\n",
      "|            Baja| 1596|\n",
      "+----------------+-----+\n",
      "\n",
      "\n",
      "--- Muestra de clientes segmentados ---\n",
      "+------------+------------+---------------+-------------------+----------------+\n",
      "|CLIENT_ID   |RECENCY_DAYS|FREQUENCY_COUNT|INTENSITY_AVG_SPEND|ACTIVITY_SEGMENT|\n",
      "+------------+------------+---------------+-------------------+----------------+\n",
      "|ES182222478Q|0           |19             |588.2236842105264  |Alta            |\n",
      "|ES182325278Y|0           |9              |625.4711111111111  |Alta            |\n",
      "|ES182133642C|0           |85             |31.129411764705882 |Alta            |\n",
      "|ES182245476M|0           |10             |0.0                |Alta            |\n",
      "|ES182413873B|0           |91             |106.26186813186811 |Alta            |\n",
      "|ES182245752Y|0           |26             |0.0                |Alta            |\n",
      "|ES182291686Y|0           |91             |26.10989010989011  |Alta            |\n",
      "|ES182232062V|0           |9              |699.2444444444444  |Alta            |\n",
      "|ES182231902V|0           |96             |0.0                |Alta            |\n",
      "|ES182279031S|0           |96             |23.79375           |Alta            |\n",
      "|ES182176939F|0           |28             |0.0                |Alta            |\n",
      "|ES182196536J|0           |7              |594.6414285714285  |Alta            |\n",
      "|ES182145473H|0           |15             |273.96733333333333 |Alta            |\n",
      "|ES182303796D|0           |93             |60.472043010752685 |Alta            |\n",
      "|ES182293250V|0           |47             |330.3663829787234  |Alta            |\n",
      "|ES182112694Y|0           |9              |0.0                |Alta            |\n",
      "|ES182297392F|0           |84             |11.445714285714287 |Alta            |\n",
      "|ES182378189N|0           |96             |13.949375000000002 |Alta            |\n",
      "|ES182186318H|0           |6              |354.57666666666665 |Alta            |\n",
      "|ES182360017K|0           |96             |6.1875             |Alta            |\n",
      "+------------+------------+---------------+-------------------+----------------+\n",
      "only showing top 20 rows\n",
      "\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 6. SEGMENTACIÓN DE ACTIVIDAD\n",
    "# ==========================================\n",
    "activity_metrics = activity_metrics.withColumn(\n",
    "    \"ACTIVITY_SEGMENT\",\n",
    "    F.when((F.col(\"RECENCY_DAYS\") <= 30) & (F.col(\"FREQUENCY_COUNT\") > 5), \"Alta\")\n",
    "     .when((F.col(\"RECENCY_DAYS\") <= 90) & (F.col(\"FREQUENCY_COUNT\") > 2), \"Media\")\n",
    "     .otherwise(\"Baja\")\n",
    ")\n",
    "\n",
    "print(\"\\n================ SEGMENTACIÓN FINAL ================\\n\")\n",
    "activity_metrics.groupBy(\"ACTIVITY_SEGMENT\").count().show()\n",
    "\n",
    "print(\"\\n--- Muestra de clientes segmentados ---\")\n",
    "activity_metrics.select(\n",
    "    \"CLIENT_ID\", \"RECENCY_DAYS\", \"FREQUENCY_COUNT\", \n",
    "    \"INTENSITY_AVG_SPEND\", \"ACTIVITY_SEGMENT\"\n",
    ").orderBy(\"ACTIVITY_SEGMENT\").show(20, truncate=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "728f9610",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Archivo guardado correctamente en: Master_FinPlus_Activity.parquet\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# ==========================================\n",
    "# 7. UNIR A MASTER FINAL\n",
    "# ==========================================\n",
    "df_final = df_master.join(activity_metrics, \"CLIENT_ID\", \"left\")\n",
    "df_final.write.mode(\"overwrite\").parquet(DATA_PATH + \"Master_FinPlus_Activity.parquet\")\n",
    "\n",
    "print(\"\\nArchivo guardado correctamente en: Master_FinPlus_Activity.parquet\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d9ee14d",
   "metadata": {},
   "source": [
    "### VALOR ECONÓMICO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cacbd5ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "DATA_PATH = \"/home/jovyan/work/data/\"\n",
    "OUT_PATH = \"/home/jovyan/work/data/activity/\"  # carpeta de salida de activity/metrics\n",
    "os.makedirs(OUT_PATH, exist_ok=True)\n",
    "\n",
    "# 1) Cargar BEHAVIOURAL y MASTER si necesitas KPIs demográficos\n",
    "beh = spark.read.parquet(os.path.join(DATA_PATH, \"BEHAVIOURAL.parquet\"))\n",
    "# Aseguramos formato fecha\n",
    "beh = beh.withColumn(\"DATE\", F.to_date(\"DATE\", \"yyyy-MM-dd\"))\n",
    "\n",
    "# Master (opcional) para incorporar totales / ingresos si quieres\n",
    "master_path = os.path.join(DATA_PATH, \"curated\", \"Master_FinPlus.parquet\")\n",
    "master = None\n",
    "if os.path.exists(master_path):\n",
    "    master = spark.read.parquet(master_path)\n",
    "\n",
    "print(\"Loaded BEHAVIOURAL rows:\", beh.count(), \"  (master found?)\", master is not None)\n",
    "\n",
    "# 2) Normalizar columnas de monto / crear KPI_TOTAL_SPEND si no existe\n",
    "# (usa mismas columnas que definiste en TRATAMIENTO DE DATOS)\n",
    "beh = beh.withColumn(\"CREDIT_CARD_DRAWINGS_ATM\", F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_ATM\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDIT_CARD_DRAWINGS_POS\", F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_POS\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDIT_CARD_DRAWINGS_OTHER\", F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS_OTHER\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDIT_CARD_DRAWINGS\", F.coalesce(F.col(\"CREDIT_CARD_DRAWINGS\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDIT_CARD_PAYMENT\", F.coalesce(F.col(\"CREDIT_CARD_PAYMENT\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDICT_CARD_BALANCE\", F.coalesce(F.col(\"CREDICT_CARD_BALANCE\"), F.lit(0.0))) \\\n",
    "         .withColumn(\"CREDIT_CARD_LIMIT\", F.coalesce(F.col(\"CREDIT_CARD_LIMIT\"), F.lit(0.0)))\n",
    "\n",
    "beh = beh.withColumn(\"KPI_TOTAL_SPEND\",\n",
    "    F.when(F.col(\"CREDIT_CARD_DRAWINGS\") > 0, F.col(\"CREDIT_CARD_DRAWINGS\"))\n",
    "     .otherwise(F.col(\"CREDIT_CARD_DRAWINGS_POS\") + F.col(\"CREDIT_CARD_DRAWINGS_ATM\") + F.col(\"CREDIT_CARD_DRAWINGS_OTHER\"))\n",
    ")\n",
    "\n",
    "# Flag actividad (por fila)\n",
    "beh = beh.withColumn(\"HAS_ACTIVITY\", F.when(F.col(\"KPI_TOTAL_SPEND\") > 0, 1).otherwise(0))\n",
    "\n",
    "# 3) Agregados por cliente: monetary_total, payments_total, avg_balance, avg_limit, utilization\n",
    "agg_econ = beh.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.sum(\"KPI_TOTAL_SPEND\").alias(\"MONETARY_TOTAL\"),         # volumen total observado\n",
    "    F.sum(\"CREDIT_CARD_PAYMENT\").alias(\"TOTAL_PAYMENTS\"),    # pagos realizados (proxy recuperación)\n",
    "    F.avg(\"CREDICT_CARD_BALANCE\").alias(\"AVG_BALANCE\"),      # balance medio\n",
    "    F.avg(\"CREDIT_CARD_LIMIT\").alias(\"AVG_LIMIT\"),           # límite medio\n",
    "    F.count(F.when(F.col(\"HAS_ACTIVITY\")==1, True)).alias(\"TX_COUNT\"),\n",
    "    F.min(\"DATE\").alias(\"FIRST_TX_DATE\"),\n",
    "    F.max(\"DATE\").alias(\"LAST_TX_DATE\")\n",
    ")\n",
    "\n",
    "# Tenure en meses (si FIRST_TX_DATE existe)\n",
    "agg_econ = agg_econ.withColumn(\"TENURE_MONTHS\", \n",
    "                               F.when(F.col(\"FIRST_TX_DATE\").isNotNull(), \n",
    "                                      F.floor(F.months_between(F.col(\"LAST_TX_DATE\"), F.col(\"FIRST_TX_DATE\"))).cast(\"int\") + 1)\n",
    "                                .otherwise(F.lit(1))\n",
    "                              )\n",
    "\n",
    "# Ratios: utilization (balance/limit) y payment rate (payments / spend)\n",
    "agg_econ = agg_econ.withColumn(\"UTILIZATION\", F.when(F.col(\"AVG_LIMIT\")>0, F.col(\"AVG_BALANCE\")/F.col(\"AVG_LIMIT\")).otherwise(F.lit(0.0))) \\\n",
    "                   .withColumn(\"PAYMENT_RATE\", F.when(F.col(\"MONETARY_TOTAL\")>0, F.col(\"TOTAL_PAYMENTS\")/F.col(\"MONETARY_TOTAL\")).otherwise(F.lit(0.0))) \\\n",
    "                   .withColumn(\"ARPU_PROXY\", F.col(\"MONETARY_TOTAL\"))  # ARPU sobre periodo observado; comentado debajo\n",
    "\n",
    "# 4) ARPU / mediana / total revenue / top-decile share\n",
    "# Observed totals (period bounded by BEHAVIOURAL dataset)\n",
    "total_rev = agg_econ.agg(F.sum(\"MONETARY_TOTAL\").alias(\"TOTAL_REVENUE\")).collect()[0][\"TOTAL_REVENUE\"]\n",
    "arpu = agg_econ.agg(F.mean(\"MONETARY_TOTAL\").alias(\"ARPU\")).collect()[0][\"ARPU\"]\n",
    "median_mon = agg_econ.approxQuantile(\"MONETARY_TOTAL\", [0.5], 0.01)[0]\n",
    "p90 = agg_econ.approxQuantile(\"MONETARY_TOTAL\", [0.9], 0.01)[0]\n",
    "top10_rev = agg_econ.filter(F.col(\"MONETARY_TOTAL\") >= p90).agg(F.sum(\"MONETARY_TOTAL\").alias(\"TOP10_REV\")).collect()[0][\"TOP10_REV\"]\n",
    "top10_share = (top10_rev / total_rev) if total_rev and total_rev>0 else None\n",
    "\n",
    "print(\"\\n=== KPI GLOBAL: Valor Económico ===\")\n",
    "print(f\"Total revenue (observed in dataset): {total_rev:.2f}\")\n",
    "print(f\"ARPU (mean monetary_total per client): {arpu:.2f}\")\n",
    "print(f\"Median monetary_total: {median_mon:.2f}\")\n",
    "print(f\"90th percentile (threshold for top10): {p90:.2f}\")\n",
    "print(f\"Top10 revenue: {top10_rev:.2f}  (share: {top10_share:.2%} )\" if top10_share is not None else \"Top10 share unavailable\")\n",
    "\n",
    "# Interpretación:\n",
    "print(\"\\nInterpretación breve:\")\n",
    "print(\"- ARPU: media de ingreso por cliente en el periodo observado. OJO: si el periodo cubre varios meses, ARPU es acumulado.\")\n",
    "print(\"- top10_share alto (>50%) => dependencia alta de pocos clientes; riesgo de concentración.\")\n",
    "print(\"- PAYMENT_RATE bajo indica clientes que consumen (spend) pero pagan poco en el periodo observado; puede indicar morosidad o timing.\")\n",
    "\n",
    "# 5) Revenues por canal (POS/ATM/OTHER) - monto y % por cliente segment y global\n",
    "channel = beh.groupBy(\"CLIENT_ID\").agg(\n",
    "    F.sum(\"CREDIT_CARD_DRAWINGS_POS\").alias(\"POS_AMOUNT\"),\n",
    "    F.sum(\"CREDIT_CARD_DRAWINGS_ATM\").alias(\"ATM_AMOUNT\"),\n",
    "    F.sum(\"CREDIT_CARD_DRAWINGS_OTHER\").alias(\"OTHER_AMOUNT\")\n",
    ").withColumn(\"CHANNEL_TOTAL\", F.col(\"POS_AMOUNT\")+F.col(\"ATM_AMOUNT\")+F.col(\"OTHER_AMOUNT\"))\n",
    "\n",
    "# Global shares\n",
    "global_channels = channel.agg(\n",
    "    F.sum(\"POS_AMOUNT\").alias(\"POS_TOTAL\"),\n",
    "    F.sum(\"ATM_AMOUNT\").alias(\"ATM_TOTAL\"),\n",
    "    F.sum(\"OTHER_AMOUNT\").alias(\"OTHER_TOTAL\")\n",
    ").collect()[0]\n",
    "pos_total = global_channels[\"POS_TOTAL\"] or 0.0\n",
    "atm_total = global_channels[\"ATM_TOTAL\"] or 0.0\n",
    "other_total = global_channels[\"OTHER_TOTAL\"] or 0.0\n",
    "grand = pos_total + atm_total + other_total\n",
    "print(f\"\\nRevenue by channel (global): POS={pos_total:.2f}, ATM={atm_total:.2f}, OTHER={other_total:.2f}, grand={grand:.2f}\")\n",
    "if grand>0:\n",
    "    print(f\"Shares: POS={pos_total/grand:.2%}, ATM={atm_total/grand:.2%}, OTHER={other_total/grand:.2%}\")\n",
    "\n",
    "# 6) LTV proxy: monetary_total / tenure_months and monetary_total absolute\n",
    "# (Proxy porque no tenemos margen ni lifetime completo; es un indicador relativo)\n",
    "agg_econ = agg_econ.withColumn(\"LTV_PROXY_MONTHLY\", F.when(F.col(\"TENURE_MONTHS\")>0, F.col(\"MONETARY_TOTAL\")/F.col(\"TENURE_MONTHS\")).otherwise(F.col(\"MONETARY_TOTAL\")))\n",
    "\n",
    "# 7) High-value but low-activity identification (oportunidades)\n",
    "# Definimos high value como > 75th percentile monetary, low activity as TX_COUNT below median\n",
    "mon75 = agg_econ.approxQuantile(\"MONETARY_TOTAL\", [0.75], 0.01)[0]\n",
    "tx_med = agg_econ.approxQuantile(\"TX_COUNT\", [0.5], 0.01)[0]\n",
    "\n",
    "hv_la = agg_econ.filter((F.col(\"MONETARY_TOTAL\") > mon75) & (F.col(\"TX_COUNT\") < tx_med))\n",
    "\n",
    "print(f\"\\nHigh-value threshold (75th pct): {mon75:.2f}, TX_COUNT median: {tx_med}\")\n",
    "print(\"Ejemplos High-Value & Low-Activity (top 10 por monetary):\")\n",
    "hv_la.orderBy(F.col(\"MONETARY_TOTAL\").desc()).select(\"CLIENT_ID\",\"MONETARY_TOTAL\",\"TX_COUNT\",\"TENURE_MONTHS\",\"LTV_PROXY_MONTHLY\").show(10, truncate=False)\n",
    "\n",
    "# 8) Cohorte por primer mes de actividad -> revenue acumulado por cohorte\n",
    "cohort = beh.groupBy(\"CLIENT_ID\").agg(F.min(\"DATE\").alias(\"first_tx_date\"))\n",
    "cohort = cohort.withColumn(\"cohort_month\", F.date_format(F.col(\"first_tx_date\"), \"yyyy-MM\"))\n",
    "\n",
    "rev_by_cohort = beh.withColumn(\"cohort_month\", F.date_format(F.col(\"DATE\"), \"yyyy-MM\")) \\\n",
    "                   .join(cohort.select(\"CLIENT_ID\",\"cohort_month\").distinct(), on=\"CLIENT_ID\", how=\"left\") \\\n",
    "                   .groupBy(\"cohort_month\").agg(\n",
    "                       F.sum(\"KPI_TOTAL_SPEND\").alias(\"COHORT_REVENUE\"),\n",
    "                       F.countDistinct(\"CLIENT_ID\").alias(\"COHORT_SIZE\")\n",
    "                   ).orderBy(\"cohort_month\")\n",
    "\n",
    "print(\"\\nRevenue by cohort_month (sample):\")\n",
    "rev_by_cohort.show(20, truncate=False)\n",
    "\n",
    "# 9) Clientes con peor PAYMENT_RATE (riesgo) y con mayor MONETARY_TOTAL (impacto)\n",
    "agg_econ = agg_econ.join(channel.select(\"CLIENT_ID\",\"POS_AMOUNT\",\"ATM_AMOUNT\",\"OTHER_AMOUNT\",\"CHANNEL_TOTAL\"), \"CLIENT_ID\", \"left\")\n",
    "agg_econ = agg_econ.join(beh.groupBy(\"CLIENT_ID\").agg(F.sum(\"CREDIT_CARD_PAYMENT\").alias(\"TOTAL_PAYMENTS2\")), \"CLIENT_ID\", \"left\")\n",
    "agg_econ = agg_econ.withColumn(\"PAYMENT_RATE2\", F.when(F.col(\"MONETARY_TOTAL\")>0, F.col(\"TOTAL_PAYMENTS2\")/F.col(\"MONETARY_TOTAL\")).otherwise(0.0))\n",
    "\n",
    "print(\"\\nTop 20 clients with low payment rate but high monetary_total (priority risk):\")\n",
    "agg_econ.filter(F.col(\"PAYMENT_RATE2\") < 0.5).orderBy(F.col(\"MONETARY_TOTAL\").desc()).select(\n",
    "    \"CLIENT_ID\",\"MONETARY_TOTAL\",\"TOTAL_PAYMENTS2\",\"PAYMENT_RATE2\",\"TENURE_MONTHS\"\n",
    ").show(20, truncate=False)\n",
    "\n",
    "# 10) Guardar resultados finales (parquet) y muestra\n",
    "econ_out = agg_econ.select(\n",
    "    \"CLIENT_ID\",\"MONETARY_TOTAL\",\"TOTAL_PAYMENTS\",\"TOTAL_PAYMENTS2\",\"PAYMENT_RATE\",\"PAYMENT_RATE2\",\n",
    "    \"AVG_BALANCE\",\"AVG_LIMIT\",\"UTILIZATION\",\"TX_COUNT\",\"TENURE_MONTHS\",\"LTV_PROXY_MONTHLY\",\n",
    "    \"POS_AMOUNT\",\"ATM_AMOUNT\",\"OTHER_AMOUNT\",\"CHANNEL_TOTAL\"\n",
    ").dropDuplicates([\"CLIENT_ID\"])\n",
    "\n",
    "econ_out.repartition(50).write.mode(\"overwrite\").parquet(os.path.join(OUT_PATH, \"economic_metrics.parquet\"))\n",
    "\n",
    "print(\"\\nEconomic metrics saved to:\", os.path.join(OUT_PATH, \"economic_metrics.parquet\"))\n",
    "\n",
    "# 11) Resumen ejecutivo impreso (acciones sugeridas)\n",
    "print(\"\\n=== Resumen ejecutivo - acciones sugeridas ===\")\n",
    "print(\"- Priorizar recuperación de clientes con PAYMENT_RATE bajo y MONETARY_TOTAL alto (ver tabla anterior).\")\n",
    "print(\"- Analizar concentración: si top10_share > 40% -> diversificar fuentes de revenue.\")\n",
    "print(\"- Clientes high-value but low-activity -> ofertas de engagement personalizadas (cross-sell).\")\n",
    "print(\"- Revisar UTILIZATION elevada (>0.8) -> riesgo de sobre-endeudamiento; monitorizar límites y alertas.\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d07bfa53",
   "metadata": {},
   "source": [
    "### INTERACCIÓN Y FIDELIDAD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a021cda1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "347eb1fe",
   "metadata": {},
   "source": [
    "### RIESGO POTENCIAL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12b6da50",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "fb2dd554",
   "metadata": {},
   "source": [
    "### OPORTUNIDADES COMERCIALES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7594434c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "146bbeb0",
   "metadata": {},
   "source": [
    "### ANÁLISIS DE CAUSALIDAD / UPLIFT (para identificar qué ofertas realmente causan más retención)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b273ecd8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "97971f30",
   "metadata": {},
   "source": [
    "### EMBEDDING DE COMPORTAMIENTO - SEQUENCE MODELING - (para recomendar productos RNNs / transformers si hay consecuencias largas)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b23ef984",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1bc7331a",
   "metadata": {},
   "source": [
    "### ANOMALÍA TRANSACCIONAL (para detectar fraudes o glitches del sistema)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63a64d21",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
